{"Event":"SparkListenerLogStart","Spark Version":"3.5.1"}
{"Event":"SparkListenerResourceProfileAdded","Resource Profile Id":0,"Executor Resource Requests":{"memory":{"Resource Name":"memory","Amount":1024,"Discovery Script":"","Vendor":""},"offHeap":{"Resource Name":"offHeap","Amount":0,"Discovery Script":"","Vendor":""}},"Task Resource Requests":{"cpus":{"Resource Name":"cpus","Amount":1.0}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"306c10bfc250","Port":44053},"Maximum Memory":455501414,"Timestamp":1759075619064,"Maximum Onheap Memory":455501414,"Maximum Offheap Memory":0}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-11-openjdk-amd64","Java Version":"11.0.28 (Ubuntu)","Scala Version":"version 2.12.18"},"Spark Properties":{"spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.driver.host":"306c10bfc250","spark.serializer.objectStreamReset":"100","spark.eventLog.enabled":"true","spark.ui.port":"4040","spark.driver.port":"33843","spark.rdd.compress":"True","spark.jars":"*********(redacted)","spark.app.name":"KafkaTestStreaming","spark.app.initial.file.urls":"*********(redacted)","spark.scheduler.mode":"FIFO","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1759075618021","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.files":"*********(redacted)","spark.app.startTime":"1759075618190","spark.executor.id":"driver","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"/tmp/spark-events","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20250928160659-0004"},"Hadoop Properties":{"hadoop.service.shutdown.timeout":"30s","yarn.resourcemanager.amlauncher.thread-count":"50","yarn.sharedcache.enabled":"false","fs.s3a.connection.maximum":"96","yarn.nodemanager.numa-awareness.numactl.cmd":"/usr/bin/numactl","fs.viewfs.overload.scheme.target.o3fs.impl":"org.apache.hadoop.fs.ozone.OzoneFileSystem","fs.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms":"1000","yarn.timeline-service.timeline-client.number-of-async-entities-to-merge":"10","hadoop.security.kms.client.timeout":"60","hadoop.http.authentication.kerberos.principal":"HTTP/_HOST@LOCALHOST","mapreduce.jobhistory.loadedjob.tasks.max":"-1","yarn.resourcemanager.application-tag-based-placement.enable":"false","mapreduce.framework.name":"local","yarn.sharedcache.uploader.server.thread-count":"50","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min":"3600","yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern":"^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$","tfile.fs.output.buffer.size":"262144","yarn.app.mapreduce.am.job.task.listener.thread-count":"30","yarn.nodemanager.node-attributes.resync-interval-ms":"120000","yarn.nodemanager.container-log-monitor.interval-ms":"60000","hadoop.security.groups.cache.background.reload.threads":"3","yarn.resourcemanager.webapp.cross-origin.enabled":"false","fs.AbstractFileSystem.ftp.impl":"org.apache.hadoop.fs.ftp.FtpFs","fs.viewfs.overload.scheme.target.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","hadoop.registry.secure":"false","hadoop.shell.safely.delete.limit.num.files":"100","mapreduce.job.acl-view-job":" ","fs.s3a.s3guard.ddb.background.sleep":"25ms","fs.s3a.retry.limit":"7","mapreduce.jobhistory.loadedjobs.cache.size":"5","fs.s3a.s3guard.ddb.table.create":"false","fs.viewfs.overload.scheme.target.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.nodemanager.amrmproxy.enabled":"false","yarn.timeline-service.entity-group-fs-store.with-user-dir":"false","mapreduce.shuffle.pathcache.expire-after-access-minutes":"5","mapreduce.input.fileinputformat.split.minsize":"0","yarn.resourcemanager.container.liveness-monitor.interval-ms":"600000","yarn.resourcemanager.client.thread-count":"50","io.seqfile.compress.blocksize":"1000000","yarn.nodemanager.runtime.linux.docker.allowed-container-runtimes":"runc","fs.viewfs.overload.scheme.target.http.impl":"org.apache.hadoop.fs.http.HttpFileSystem","yarn.resourcemanager.nodemanagers.heartbeat-interval-slowdown-factor":"1.0","yarn.sharedcache.checksum.algo.impl":"org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl","yarn.nodemanager.amrmproxy.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor","yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size":"10485760","mapreduce.reduce.shuffle.fetch.retry.interval-ms":"1000","mapreduce.task.profile.maps":"0-2","yarn.scheduler.include-port-in-node-name":"false","yarn.nodemanager.admin-env":"MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX","yarn.resourcemanager.node-removal-untracked.timeout-ms":"60000","mapreduce.am.max-attempts":"2","hadoop.security.kms.client.failover.sleep.base.millis":"100","mapreduce.jobhistory.webapp.https.address":"0.0.0.0:19890","yarn.node-labels.fs-store.impl.class":"org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore","yarn.nodemanager.collector-service.address":"${yarn.nodemanager.hostname}:8048","fs.trash.checkpoint.interval":"0","mapreduce.job.map.output.collector.class":"org.apache.hadoop.mapred.MapTask$MapOutputBuffer","yarn.resourcemanager.node-ip-cache.expiry-interval-secs":"-1","hadoop.http.authentication.signature.secret.file":"*********(redacted)","hadoop.jetty.logs.serve.aliases":"true","yarn.resourcemanager.placement-constraints.handler":"disabled","yarn.timeline-service.handler-thread-count":"10","yarn.resourcemanager.max-completed-applications":"1000","yarn.nodemanager.aux-services.manifest.enabled":"false","yarn.resourcemanager.system-metrics-publisher.enabled":"false","yarn.resourcemanager.placement-constraints.algorithm.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm","yarn.sharedcache.webapp.address":"0.0.0.0:8788","fs.s3a.select.input.csv.quote.escape.character":"\\\\","yarn.resourcemanager.delegation.token.renew-interval":"*********(redacted)","yarn.sharedcache.nm.uploader.replication.factor":"10","hadoop.security.groups.negative-cache.secs":"30","yarn.app.mapreduce.task.container.log.backups":"0","mapreduce.reduce.skip.proc-count.auto-incr":"true","fs.viewfs.overload.scheme.target.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","hadoop.security.group.mapping.ldap.posix.attr.gid.name":"gidNumber","ipc.client.fallback-to-simple-auth-allowed":"false","yarn.nodemanager.resource.memory.enforced":"true","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.enable-batch":"false","yarn.client.failover-proxy-provider":"org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider","yarn.timeline-service.http-authentication.simple.anonymous.allowed":"true","ha.health-monitor.check-interval.ms":"1000","yarn.nodemanager.runtime.linux.runc.host-pid-namespace.allowed":"false","hadoop.metrics.jvm.use-thread-mxbean":"false","ipc.[port_number].faircallqueue.multiplexer.weights":"8,4,2,1","yarn.acl.reservation-enable":"false","yarn.resourcemanager.store.class":"org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore","yarn.app.mapreduce.am.hard-kill-timeout-ms":"10000","fs.s3a.etag.checksum.enabled":"false","yarn.nodemanager.container-metrics.enable":"true","ha.health-monitor.rpc.connect.max.retries":"1","yarn.timeline-service.client.fd-clean-interval-secs":"60","yarn.resourcemanager.nodemanagers.heartbeat-interval-scaling-enable":"false","yarn.resourcemanager.nodemanagers.heartbeat-interval-ms":"1000","hadoop.common.configuration.version":"3.0.0","fs.s3a.s3guard.ddb.table.capacity.read":"0","yarn.nodemanager.remote-app-log-dir-suffix":"logs","yarn.nodemanager.container-log-monitor.dir-size-limit-bytes":"1000000000","yarn.nodemanager.windows-container.cpu-limit.enabled":"false","yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed":"false","file.blocksize":"67108864","hadoop.http.idle_timeout.ms":"60000","hadoop.registry.zk.retry.ceiling.ms":"60000","yarn.scheduler.configuration.leveldb-store.path":"${hadoop.tmp.dir}/yarn/system/confstore","yarn.sharedcache.store.in-memory.initial-delay-mins":"10","mapreduce.jobhistory.principal":"jhs/_HOST@REALM.TLD","mapreduce.map.skip.proc-count.auto-incr":"true","fs.s3a.committer.name":"file","mapreduce.task.profile.reduces":"0-2","hadoop.zk.num-retries":"1000","yarn.webapp.xfs-filter.enabled":"true","fs.viewfs.overload.scheme.target.hdfs.impl":"org.apache.hadoop.hdfs.DistributedFileSystem","seq.io.sort.mb":"100","yarn.scheduler.configuration.max.version":"100","yarn.timeline-service.webapp.https.address":"${yarn.timeline-service.hostname}:8190","yarn.resourcemanager.scheduler.address":"${yarn.resourcemanager.hostname}:8030","yarn.node-labels.enabled":"false","yarn.resourcemanager.webapp.ui-actions.enabled":"true","mapreduce.task.timeout":"600000","yarn.sharedcache.client-server.thread-count":"50","hadoop.security.groups.shell.command.timeout":"0s","hadoop.security.crypto.cipher.suite":"AES/CTR/NoPadding","yarn.nodemanager.elastic-memory-control.oom-handler":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler","yarn.resourcemanager.connect.max-wait.ms":"900000","fs.defaultFS":"file:///","yarn.minicluster.use-rpc":"false","ipc.[port_number].decay-scheduler.decay-factor":"0.5","fs.har.impl.disable.cache":"true","yarn.webapp.ui2.enable":"false","io.compression.codec.bzip2.library":"system-native","yarn.webapp.filter-invalid-xml-chars":"false","yarn.nodemanager.runtime.linux.runc.layer-mounts-interval-secs":"600","fs.s3a.select.input.csv.record.delimiter":"\\n","fs.s3a.change.detection.source":"etag","ipc.[port_number].backoff.enable":"false","yarn.nodemanager.distributed-scheduling.enabled":"false","mapreduce.shuffle.connection-keep-alive.timeout":"5","yarn.resourcemanager.webapp.https.address":"${yarn.resourcemanager.hostname}:8090","yarn.webapp.enable-rest-app-submissions":"true","mapreduce.jobhistory.address":"0.0.0.0:10020","yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.is.minicluster":"false","yarn.nodemanager.address":"${yarn.nodemanager.hostname}:0","fs.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","fs.AbstractFileSystem.s3a.impl":"org.apache.hadoop.fs.s3a.S3A","mapreduce.task.combine.progress.records":"10000","yarn.resourcemanager.epoch.range":"0","yarn.resourcemanager.am.max-attempts":"2","yarn.nodemanager.runtime.linux.runc.image-toplevel-dir":"/runc-root","yarn.nodemanager.linux-container-executor.cgroups.hierarchy":"/hadoop-yarn","fs.AbstractFileSystem.wasbs.impl":"org.apache.hadoop.fs.azure.Wasbs","yarn.timeline-service.entity-group-fs-store.cache-store-class":"org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore","yarn.nodemanager.runtime.linux.runc.allowed-container-networks":"host,none,bridge","fs.ftp.transfer.mode":"BLOCK_TRANSFER_MODE","ipc.server.log.slow.rpc":"false","ipc.server.reuseaddr":"true","fs.ftp.timeout":"0","yarn.resourcemanager.node-labels.provider.fetch-interval-ms":"1800000","yarn.router.webapp.https.address":"0.0.0.0:8091","yarn.nodemanager.webapp.cross-origin.enabled":"false","fs.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","yarn.resourcemanager.auto-update.containers":"false","yarn.app.mapreduce.am.job.committer.cancel-timeout":"60000","yarn.scheduler.configuration.zk-store.parent-path":"/confstore","yarn.nodemanager.default-container-executor.log-dirs.permissions":"710","yarn.app.attempt.diagnostics.limit.kc":"64","fs.viewfs.overload.scheme.target.swebhdfs.impl":"org.apache.hadoop.hdfs.web.SWebHdfsFileSystem","yarn.client.failover-no-ha-proxy-provider":"org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider","fs.s3a.change.detection.mode":"server","ftp.bytes-per-checksum":"512","yarn.nodemanager.resource.memory-mb":"-1","fs.AbstractFileSystem.abfs.impl":"org.apache.hadoop.fs.azurebfs.Abfs","yarn.timeline-service.writer.flush-interval-seconds":"60","fs.s3a.fast.upload.active.blocks":"4","yarn.resourcemanager.submission-preprocessor.enabled":"false","hadoop.security.credential.clear-text-fallback":"true","yarn.nodemanager.collector-service.thread-count":"5","ipc.[port_number].scheduler.impl":"org.apache.hadoop.ipc.DefaultRpcScheduler","fs.azure.secure.mode":"false","mapreduce.jobhistory.joblist.cache.size":"20000","fs.ftp.host":"0.0.0.0","yarn.timeline-service.writer.async.queue.capacity":"100","yarn.resourcemanager.fs.state-store.num-retries":"0","yarn.resourcemanager.nodemanager-connect-retries":"10","yarn.nodemanager.log-aggregation.num-log-files-per-app":"30","hadoop.security.kms.client.encrypted.key.cache.low-watermark":"0.3f","fs.s3a.committer.magic.enabled":"true","yarn.timeline-service.client.max-retries":"30","dfs.ha.fencing.ssh.connect-timeout":"30000","yarn.log-aggregation-enable":"false","yarn.system-metrics-publisher.enabled":"false","mapreduce.reduce.markreset.buffer.percent":"0.0","fs.AbstractFileSystem.viewfs.impl":"org.apache.hadoop.fs.viewfs.ViewFs","yarn.resourcemanager.nodemanagers.heartbeat-interval-speedup-factor":"1.0","mapreduce.task.io.sort.factor":"10","yarn.nodemanager.amrmproxy.client.thread-count":"25","ha.failover-controller.new-active.rpc-timeout.ms":"60000","yarn.nodemanager.container-localizer.java.opts":"-Xmx256m","mapreduce.jobhistory.datestring.cache.size":"200000","mapreduce.job.acl-modify-job":" ","yarn.nodemanager.windows-container.memory-limit.enabled":"false","yarn.timeline-service.webapp.address":"${yarn.timeline-service.hostname}:8188","yarn.app.mapreduce.am.job.committer.commit-window":"10000","yarn.nodemanager.container-manager.thread-count":"20","yarn.minicluster.fixed.ports":"false","hadoop.tags.system":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.cluster.max-application-priority":"0","yarn.timeline-service.ttl-enable":"true","mapreduce.jobhistory.recovery.store.fs.uri":"${hadoop.tmp.dir}/mapred/history/recoverystore","hadoop.caller.context.signature.max.size":"40","ipc.[port_number].decay-scheduler.backoff.responsetime.enable":"false","yarn.client.load.resource-types.from-server":"false","ha.zookeeper.session-timeout.ms":"10000","ipc.[port_number].decay-scheduler.metrics.top.user.count":"10","tfile.io.chunk.size":"1048576","fs.s3a.s3guard.ddb.table.capacity.write":"0","yarn.dispatcher.print-events-info.threshold":"5000","mapreduce.job.speculative.slowtaskthreshold":"1.0","io.serializations":"org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization","hadoop.security.kms.client.failover.sleep.max.millis":"2000","hadoop.security.group.mapping.ldap.directory.search.timeout":"10000","yarn.scheduler.configuration.store.max-logs":"1000","yarn.nodemanager.node-attributes.provider.fetch-interval-ms":"600000","fs.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","yarn.nodemanager.local-cache.max-files-per-directory":"8192","hadoop.http.cross-origin.enabled":"false","hadoop.zk.acl":"world:anyone:rwcda","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache":"10","mapreduce.map.sort.spill.percent":"0.80","yarn.timeline-service.entity-group-fs-store.scan-interval-seconds":"60","yarn.node-attribute.fs-store.impl.class":"org.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore","fs.s3a.retry.interval":"500ms","yarn.timeline-service.client.best-effort":"false","yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled":"*********(redacted)","hadoop.security.group.mapping.ldap.posix.attr.uid.name":"uidNumber","fs.AbstractFileSystem.swebhdfs.impl":"org.apache.hadoop.fs.SWebHdfs","yarn.nodemanager.elastic-memory-control.timeout-sec":"5","fs.s3a.select.enabled":"true","mapreduce.ifile.readahead":"true","yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms":"300000","yarn.timeline-service.reader.webapp.address":"${yarn.timeline-service.webapp.address}","yarn.resourcemanager.placement-constraints.algorithm.pool-size":"1","yarn.timeline-service.hbase.coprocessor.jar.hdfs.location":"/hbase/coprocessor/hadoop-yarn-server-timelineservice.jar","hadoop.security.kms.client.encrypted.key.cache.num.refill.threads":"2","yarn.resourcemanager.scheduler.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler","yarn.app.mapreduce.am.command-opts":"-Xmx1024m","fs.s3a.metadatastore.fail.on.write.error":"true","hadoop.http.sni.host.check.enabled":"false","mapreduce.cluster.local.dir":"${hadoop.tmp.dir}/mapred/local","io.mapfile.bloom.error.rate":"0.005","fs.client.resolve.topology.enabled":"false","yarn.nodemanager.runtime.linux.allowed-runtimes":"default","yarn.sharedcache.store.class":"org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore","ha.failover-controller.graceful-fence.rpc-timeout.ms":"5000","ftp.replication":"3","fs.getspaceused.jitterMillis":"60000","hadoop.security.uid.cache.secs":"14400","mapreduce.job.maxtaskfailures.per.tracker":"3","fs.s3a.metadatastore.impl":"org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore","io.skip.checksum.errors":"false","yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts":"3","yarn.timeline-service.webapp.xfs-filter.xframe-options":"SAMEORIGIN","fs.s3a.connection.timeout":"200000","yarn.app.mapreduce.am.webapp.https.enabled":"false","mapreduce.job.max.split.locations":"15","yarn.resourcemanager.nm-container-queuing.max-queue-length":"15","yarn.resourcemanager.delegation-token.always-cancel":"*********(redacted)","hadoop.registry.zk.session.timeout.ms":"60000","yarn.federation.cache-ttl.secs":"300","mapreduce.jvm.system-properties-to-log":"os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name","yarn.resourcemanager.opportunistic-container-allocation.nodes-used":"10","yarn.timeline-service.entity-group-fs-store.active-dir":"/tmp/entity-file-history/active","mapreduce.shuffle.transfer.buffer.size":"131072","yarn.timeline-service.client.retry-interval-ms":"1000","yarn.timeline-service.flowname.max-size":"0","yarn.http.policy":"HTTP_ONLY","fs.s3a.socket.send.buffer":"8192","fs.AbstractFileSystem.abfss.impl":"org.apache.hadoop.fs.azurebfs.Abfss","yarn.sharedcache.uploader.server.address":"0.0.0.0:8046","yarn.resourcemanager.delegation-token.max-conf-size-bytes":"*********(redacted)","hadoop.http.authentication.token.validity":"*********(redacted)","mapreduce.shuffle.max.connections":"0","yarn.minicluster.yarn.nodemanager.resource.memory-mb":"4096","mapreduce.job.emit-timeline-data":"false","yarn.nodemanager.resource.system-reserved-memory-mb":"-1","hadoop.kerberos.min.seconds.before.relogin":"60","mapreduce.jobhistory.move.thread-count":"3","yarn.resourcemanager.admin.client.thread-count":"1","yarn.dispatcher.drain-events.timeout":"300000","ipc.[port_number].decay-scheduler.backoff.responsetime.thresholds":"10s,20s,30s,40s","fs.s3a.buffer.dir":"${hadoop.tmp.dir}/s3a","hadoop.ssl.enabled.protocols":"TLSv1.2","mapreduce.jobhistory.admin.address":"0.0.0.0:10033","yarn.log-aggregation-status.time-out.ms":"600000","fs.s3a.accesspoint.required":"false","mapreduce.shuffle.port":"13562","yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory":"10","yarn.nodemanager.health-checker.interval-ms":"600000","yarn.resourcemanager.proxy.connection.timeout":"60000","yarn.router.clientrm.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor","yarn.resourcemanager.zk-appid-node.split-index":"0","ftp.blocksize":"67108864","yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions":"read","yarn.router.rmadmin.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor","yarn.nodemanager.log-container-debug-info.enabled":"true","yarn.resourcemanager.activities-manager.app-activities.max-queue-length":"100","yarn.resourcemanager.application-https.policy":"NONE","yarn.client.max-cached-nodemanagers-proxies":"0","yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms":"20","yarn.nodemanager.delete.debug-delay-sec":"0","yarn.nodemanager.pmem-check-enabled":"true","yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage":"90.0","mapreduce.app-submission.cross-platform":"false","yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms":"10000","yarn.nodemanager.container-retry-minimum-interval-ms":"1000","hadoop.security.groups.cache.secs":"300","yarn.federation.enabled":"false","yarn.workflow-id.tag-prefix":"workflowid:","fs.azure.local.sas.key.mode":"false","ipc.maximum.data.length":"134217728","fs.s3a.endpoint":"s3.amazonaws.com","mapreduce.shuffle.max.threads":"0","yarn.router.pipeline.cache-max-size":"25","yarn.resourcemanager.nm-container-queuing.load-comparator":"QUEUE_LENGTH","yarn.resourcemanager.resource-tracker.nm.ip-hostname-check":"false","hadoop.security.authorization":"false","mapreduce.job.complete.cancel.delegation.tokens":"*********(redacted)","fs.s3a.paging.maximum":"5000","nfs.exports.allowed.hosts":"* rw","yarn.nodemanager.amrmproxy.ha.enable":"false","fs.AbstractFileSystem.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","mapreduce.jobhistory.http.policy":"HTTP_ONLY","yarn.sharedcache.store.in-memory.check-period-mins":"720","hadoop.security.group.mapping.ldap.ssl":"false","fs.s3a.downgrade.syncable.exceptions":"true","yarn.client.application-client-protocol.poll-interval-ms":"200","yarn.scheduler.configuration.leveldb-store.compaction-interval-secs":"86400","yarn.timeline-service.writer.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl","ha.zookeeper.parent-znode":"/hadoop-ha","yarn.resourcemanager.submission-preprocessor.file-refresh-interval-ms":"60000","yarn.nodemanager.log-aggregation.policy.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy","mapreduce.reduce.shuffle.merge.percent":"0.66","hadoop.security.group.mapping.ldap.search.filter.group":"(objectClass=group)","yarn.resourcemanager.placement-constraints.scheduler.pool-size":"1","yarn.resourcemanager.activities-manager.cleanup-interval-ms":"5000","yarn.nodemanager.resourcemanager.minimum.version":"NONE","mapreduce.job.speculative.speculative-cap-running-tasks":"0.1","yarn.admin.acl":"*","ipc.[port_number].identity-provider.impl":"org.apache.hadoop.ipc.UserIdentityProvider","yarn.nodemanager.recovery.supervised":"false","yarn.sharedcache.admin.thread-count":"1","yarn.resourcemanager.ha.automatic-failover.enabled":"true","yarn.nodemanager.container-log-monitor.total-size-limit-bytes":"10000000000","mapreduce.reduce.skip.maxgroups":"0","mapreduce.reduce.shuffle.connect.timeout":"180000","yarn.nodemanager.health-checker.scripts":"script","yarn.resourcemanager.address":"${yarn.resourcemanager.hostname}:8032","ipc.client.ping":"true","mapreduce.task.local-fs.write-limit.bytes":"-1","fs.adl.oauth2.access.token.provider.type":"*********(redacted)","mapreduce.shuffle.ssl.file.buffer.size":"65536","yarn.resourcemanager.ha.automatic-failover.embedded":"true","yarn.nodemanager.resource-plugins.gpu.docker-plugin":"nvidia-docker-v1","fs.s3a.s3guard.consistency.retry.interval":"2s","fs.s3a.multipart.purge":"false","yarn.scheduler.configuration.store.class":"file","yarn.resourcemanager.nm-container-queuing.queue-limit-stdev":"1.0f","mapreduce.job.end-notification.max.attempts":"5","mapreduce.output.fileoutputformat.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled":"false","ipc.client.bind.wildcard.addr":"false","yarn.resourcemanager.webapp.rest-csrf.enabled":"false","ha.health-monitor.connect-retry-interval.ms":"1000","yarn.nodemanager.keytab":"/etc/krb5.keytab","mapreduce.jobhistory.keytab":"/etc/security/keytab/jhs.service.keytab","fs.s3a.threads.max":"64","yarn.nodemanager.runtime.linux.docker.image-update":"false","mapreduce.reduce.shuffle.input.buffer.percent":"0.70","fs.viewfs.overload.scheme.target.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","yarn.dispatcher.cpu-monitor.samples-per-min":"60","hadoop.security.token.service.use_ip":"*********(redacted)","yarn.nodemanager.runtime.linux.docker.allowed-container-networks":"host,none,bridge","yarn.nodemanager.node-labels.resync-interval-ms":"120000","hadoop.tmp.dir":"/tmp/hadoop-${user.name}","mapreduce.job.maps":"2","mapreduce.jobhistory.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.job.end-notification.max.retry.interval":"5000","yarn.log-aggregation.retain-check-interval-seconds":"-1","yarn.resourcemanager.resource-tracker.client.thread-count":"50","yarn.nodemanager.containers-launcher.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher","yarn.rm.system-metrics-publisher.emit-container-events":"false","yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size":"10000","yarn.resourcemanager.ha.automatic-failover.zk-base-path":"/yarn-leader-election","io.seqfile.local.dir":"${hadoop.tmp.dir}/io/local","fs.s3a.s3guard.ddb.throttle.retry.interval":"100ms","fs.AbstractFileSystem.wasb.impl":"org.apache.hadoop.fs.azure.Wasb","mapreduce.client.submit.file.replication":"10","mapreduce.jobhistory.minicluster.fixed.ports":"false","fs.s3a.multipart.threshold":"128M","yarn.resourcemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","mapreduce.jobhistory.done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done","ipc.server.purge.interval":"15","ipc.client.idlethreshold":"4000","yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage":"false","mapreduce.reduce.input.buffer.percent":"0.0","yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold":"1","yarn.nodemanager.webapp.rest-csrf.enabled":"false","fs.ftp.host.port":"21","ipc.ping.interval":"60000","yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size":"10","yarn.resourcemanager.admin.address":"${yarn.resourcemanager.hostname}:8033","file.client-write-packet-size":"65536","ipc.client.kill.max":"10","mapreduce.reduce.speculative":"true","hadoop.security.key.default.bitlength":"128","mapreduce.job.reducer.unconditional-preempt.delay.sec":"300","yarn.nodemanager.disk-health-checker.interval-ms":"120000","yarn.nodemanager.log.deletion-threads-count":"4","fs.s3a.committer.abort.pending.uploads":"true","yarn.webapp.filter-entity-list-by-user":"false","yarn.resourcemanager.activities-manager.app-activities.ttl-ms":"600000","ipc.client.connection.maxidletime":"10000","mapreduce.task.io.sort.mb":"100","yarn.nodemanager.localizer.client.thread-count":"5","io.erasurecode.codec.rs.rawcoders":"rs_native,rs_java","io.erasurecode.codec.rs-legacy.rawcoders":"rs-legacy_java","yarn.sharedcache.admin.address":"0.0.0.0:8047","yarn.resourcemanager.placement-constraints.algorithm.iterator":"SERIAL","yarn.nodemanager.localizer.cache.cleanup.interval-ms":"600000","hadoop.security.crypto.codec.classes.aes.ctr.nopadding":"org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec","mapreduce.job.cache.limit.max-resources-mb":"0","fs.s3a.connection.ssl.enabled":"true","yarn.nodemanager.process-kill-wait.ms":"5000","mapreduce.job.hdfs-servers":"${fs.defaultFS}","yarn.app.mapreduce.am.webapp.https.client.auth":"false","hadoop.workaround.non.threadsafe.getpwuid":"true","fs.df.interval":"60000","ipc.[port_number].decay-scheduler.thresholds":"13,25,50","fs.s3a.multiobjectdelete.enable":"true","yarn.sharedcache.cleaner.resource-sleep-ms":"0","yarn.nodemanager.disk-health-checker.min-healthy-disks":"0.25","hadoop.shell.missing.defaultFs.warning":"false","io.file.buffer.size":"65536","fs.viewfs.overload.scheme.target.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","hadoop.security.group.mapping.ldap.search.attr.member":"member","hadoop.security.random.device.file.path":"/dev/urandom","hadoop.security.sensitive-config-keys":"*********(redacted)","fs.s3a.s3guard.ddb.max.retries":"9","fs.viewfs.overload.scheme.target.file.impl":"org.apache.hadoop.fs.LocalFileSystem","hadoop.rpc.socket.factory.class.default":"org.apache.hadoop.net.StandardSocketFactory","yarn.intermediate-data-encryption.enable":"false","yarn.resourcemanager.connect.retry-interval.ms":"30000","yarn.nodemanager.container.stderr.pattern":"{*stderr*,*STDERR*}","yarn.scheduler.minimum-allocation-mb":"1024","yarn.app.mapreduce.am.staging-dir":"/tmp/hadoop-yarn/staging","mapreduce.reduce.shuffle.read.timeout":"180000","hadoop.http.cross-origin.max-age":"1800","io.erasurecode.codec.xor.rawcoders":"xor_native,xor_java","fs.s3a.s3guard.consistency.retry.limit":"7","fs.s3a.connection.establish.timeout":"5000","mapreduce.job.running.map.limit":"0","yarn.minicluster.control-resource-monitoring":"false","hadoop.ssl.require.client.cert":"false","hadoop.kerberos.kinit.command":"kinit","yarn.federation.state-store.class":"org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore","mapreduce.reduce.log.level":"INFO","hadoop.security.dns.log-slow-lookups.threshold.ms":"1000","mapreduce.job.ubertask.enable":"false","adl.http.timeout":"-1","yarn.resourcemanager.placement-constraints.retry-attempts":"3","hadoop.caller.context.enabled":"false","hadoop.security.group.mapping.ldap.num.attempts":"3","yarn.nodemanager.vmem-pmem-ratio":"2.1","hadoop.rpc.protection":"authentication","ha.health-monitor.rpc-timeout.ms":"45000","yarn.nodemanager.remote-app-log-dir":"/tmp/logs","hadoop.zk.timeout-ms":"10000","fs.s3a.s3guard.cli.prune.age":"86400000","yarn.nodemanager.resource.pcores-vcores-multiplier":"1.0","yarn.nodemanager.runtime.linux.sandbox-mode":"disabled","yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size":"10","fs.viewfs.overload.scheme.target.webhdfs.impl":"org.apache.hadoop.hdfs.web.WebHdfsFileSystem","fs.s3a.committer.threads":"8","hadoop.zk.retry-interval-ms":"1000","hadoop.security.crypto.buffer.size":"8192","yarn.nodemanager.node-labels.provider.fetch-interval-ms":"600000","mapreduce.jobhistory.recovery.store.leveldb.path":"${hadoop.tmp.dir}/mapred/history/recoverystore","yarn.client.failover-retries-on-socket-timeouts":"0","fs.s3a.ssl.channel.mode":"default_jsse","yarn.nodemanager.resource.memory.enabled":"false","fs.azure.authorization.caching.enable":"true","hadoop.security.instrumentation.requires.admin":"false","yarn.nodemanager.delete.thread-count":"4","mapreduce.job.finish-when-all-reducers-done":"true","hadoop.registry.jaas.context":"Client","yarn.timeline-service.leveldb-timeline-store.path":"${hadoop.tmp.dir}/yarn/timeline","io.map.index.interval":"128","yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms":"100","fs.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","mapreduce.job.counters.max":"120","mapreduce.jobhistory.webapp.rest-csrf.enabled":"false","yarn.timeline-service.store-class":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.jobhistory.move.interval-ms":"180000","fs.s3a.change.detection.version.required":"true","yarn.nodemanager.localizer.fetch.thread-count":"4","yarn.resourcemanager.scheduler.client.thread-count":"50","hadoop.ssl.hostname.verifier":"DEFAULT","yarn.timeline-service.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/timeline","mapreduce.job.classloader":"false","mapreduce.task.profile.map.params":"${mapreduce.task.profile.params}","ipc.client.connect.timeout":"20000","hadoop.security.auth_to_local.mechanism":"hadoop","yarn.timeline-service.app-collector.linger-period.ms":"60000","yarn.nm.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.reservation-system.planfollower.time-step":"1000","yarn.resourcemanager.proxy.timeout.enabled":"true","yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms":"600000","yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed":"true","yarn.webapp.api-service.enable":"false","yarn.nodemanager.recovery.enabled":"false","mapreduce.job.end-notification.retry.interval":"1000","fs.du.interval":"600000","fs.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","yarn.nodemanager.container.stderr.tail.bytes":"4096","yarn.nodemanager.disk-health-checker.disk-free-space-threshold.enabled":"true","hadoop.security.group.mapping.ldap.read.timeout.ms":"60000","hadoop.security.groups.cache.warn.after.ms":"5000","file.bytes-per-checksum":"512","mapreduce.outputcommitter.factory.scheme.s3a":"org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory","hadoop.security.groups.cache.background.reload":"false","yarn.nodemanager.container-monitor.enabled":"true","yarn.nodemanager.elastic-memory-control.enabled":"false","net.topology.script.number.args":"100","mapreduce.task.merge.progress.records":"10000","yarn.nodemanager.localizer.address":"${yarn.nodemanager.hostname}:8040","yarn.timeline-service.keytab":"/etc/krb5.keytab","mapreduce.reduce.shuffle.fetch.retry.timeout-ms":"30000","yarn.resourcemanager.rm.container-allocation.expiry-interval-ms":"600000","yarn.nodemanager.container-executor.exit-code-file.timeout-ms":"2000","mapreduce.fileoutputcommitter.algorithm.version":"1","yarn.resourcemanager.work-preserving-recovery.enabled":"true","mapreduce.map.skip.maxrecords":"0","yarn.sharedcache.root-dir":"/sharedcache","fs.s3a.retry.throttle.limit":"20","hadoop.http.authentication.type":"simple","fs.viewfs.overload.scheme.target.oss.impl":"org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem","mapreduce.job.cache.limit.max-resources":"0","mapreduce.task.userlog.limit.kb":"0","ipc.[port_number].weighted-cost.handler":"1","yarn.resourcemanager.scheduler.monitor.enable":"false","ipc.client.connect.max.retries":"10","hadoop.registry.zk.retry.times":"5","yarn.nodemanager.resource-monitor.interval-ms":"3000","yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices":"auto","mapreduce.job.sharedcache.mode":"disabled","yarn.nodemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.shuffle.listen.queue.size":"128","yarn.scheduler.configuration.mutation.acl-policy.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy","mapreduce.map.cpu.vcores":"1","yarn.log-aggregation.file-formats":"TFile","yarn.timeline-service.client.fd-retain-secs":"300","fs.s3a.select.output.csv.field.delimiter":",","yarn.nodemanager.health-checker.timeout-ms":"1200000","hadoop.user.group.static.mapping.overrides":"dr.who=;","fs.azure.sas.expiry.period":"90d","fs.s3a.select.output.csv.record.delimiter":"\\n","mapreduce.jobhistory.recovery.store.class":"org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService","fs.viewfs.overload.scheme.target.https.impl":"org.apache.hadoop.fs.http.HttpsFileSystem","fs.s3a.s3guard.ddb.table.sse.enabled":"false","yarn.resourcemanager.fail-fast":"${yarn.fail-fast}","yarn.resourcemanager.proxy-user-privileges.enabled":"false","yarn.router.webapp.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST","yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage":"90.0","mapreduce.job.reducer.preempt.delay.sec":"0","hadoop.util.hash.type":"murmur","yarn.nodemanager.disk-validator":"basic","yarn.app.mapreduce.client.job.max-retries":"3","fs.viewfs.overload.scheme.target.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","mapreduce.reduce.shuffle.retry-delay.max.ms":"60000","hadoop.security.group.mapping.ldap.connection.timeout.ms":"60000","mapreduce.task.profile.params":"-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s","yarn.app.mapreduce.shuffle.log.backups":"0","yarn.nodemanager.container-diagnostics-maximum-size":"10000","hadoop.registry.zk.retry.interval.ms":"1000","yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms":"1000","fs.AbstractFileSystem.file.impl":"org.apache.hadoop.fs.local.LocalFs","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds":"-1","mapreduce.jobhistory.cleaner.interval-ms":"86400000","hadoop.registry.zk.quorum":"localhost:2181","yarn.nodemanager.runtime.linux.runc.allowed-container-runtimes":"runc","mapreduce.output.fileoutputformat.compress":"false","yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs":"*********(redacted)","fs.s3a.assumed.role.session.duration":"30m","hadoop.security.group.mapping.ldap.conversion.rule":"none","hadoop.ssl.server.conf":"ssl-server.xml","fs.s3a.retry.throttle.interval":"100ms","seq.io.sort.factor":"100","fs.viewfs.overload.scheme.target.ofs.impl":"org.apache.hadoop.fs.ozone.RootedOzoneFileSystem","yarn.sharedcache.cleaner.initial-delay-mins":"10","mapreduce.client.completion.pollinterval":"5000","hadoop.ssl.keystores.factory.class":"org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory","yarn.app.mapreduce.am.resource.cpu-vcores":"1","yarn.timeline-service.enabled":"false","yarn.nodemanager.runtime.linux.docker.capabilities":"CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE","yarn.acl.enable":"false","yarn.timeline-service.entity-group-fs-store.done-dir":"/tmp/entity-file-history/done/","hadoop.security.group.mapping.ldap.num.attempts.before.failover":"3","mapreduce.task.profile":"false","hadoop.prometheus.endpoint.enabled":"false","yarn.resourcemanager.fs.state-store.uri":"${hadoop.tmp.dir}/yarn/system/rmstore","mapreduce.jobhistory.always-scan-user-dir":"false","fs.s3a.metadatastore.metadata.ttl":"15m","yarn.nodemanager.opportunistic-containers-use-pause-for-preemption":"false","yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user":"nobody","yarn.timeline-service.reader.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl","yarn.resourcemanager.configuration.provider-class":"org.apache.hadoop.yarn.LocalConfigurationProvider","yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold":"1","yarn.resourcemanager.configuration.file-system-based-store":"/yarn/conf","mapreduce.job.cache.limit.max-single-resource-mb":"0","yarn.nodemanager.runtime.linux.docker.stop.grace-period":"10","yarn.resourcemanager.resource-profiles.source-file":"resource-profiles.json","mapreduce.job.dfs.storage.capacity.kill-limit-exceed":"false","yarn.nodemanager.resource.percentage-physical-cpu-limit":"100","mapreduce.jobhistory.client.thread-count":"10","tfile.fs.input.buffer.size":"262144","mapreduce.client.progressmonitor.pollinterval":"1000","yarn.nodemanager.log-dirs":"${yarn.log.dir}/userlogs","yarn.resourcemanager.opportunistic.max.container-allocation.per.am.heartbeat":"-1","fs.automatic.close":"true","yarn.resourcemanager.delegation-token-renewer.thread-retry-interval":"*********(redacted)","fs.s3a.select.input.csv.quote.character":"\"","yarn.nodemanager.hostname":"0.0.0.0","ipc.[port_number].cost-provider.impl":"org.apache.hadoop.ipc.DefaultCostProvider","yarn.nodemanager.runtime.linux.runc.manifest-to-resources-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.HdfsManifestToResourcesPlugin","yarn.nodemanager.remote-app-log-dir-include-older":"true","yarn.nodemanager.resource.memory.cgroups.swappiness":"0","ftp.stream-buffer-size":"4096","yarn.fail-fast":"false","yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep":"100","yarn.timeline-service.app-aggregation-interval-secs":"15","hadoop.security.group.mapping.ldap.search.filter.user":"(&(objectClass=user)(sAMAccountName={0}))","ipc.[port_number].weighted-cost.lockshared":"10","yarn.nodemanager.container-localizer.log.level":"INFO","yarn.timeline-service.address":"${yarn.timeline-service.hostname}:10200","mapreduce.job.ubertask.maxmaps":"9","fs.s3a.threads.keepalivetime":"60","mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.task.files.preserve.failedtasks":"false","yarn.app.mapreduce.client.job.retry-interval":"2000","ha.failover-controller.graceful-fence.connection.retries":"1","fs.s3a.select.output.csv.quote.escape.character":"\\\\","yarn.resourcemanager.delegation.token.max-lifetime":"*********(redacted)","hadoop.kerberos.keytab.login.autorenewal.enabled":"false","yarn.timeline-service.client.drain-entities.timeout.ms":"2000","yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin","yarn.resourcemanager.nodemanagers.heartbeat-interval-min-ms":"1000","yarn.timeline-service.entity-group-fs-store.summary-store":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.reduce.cpu.vcores":"1","mapreduce.job.encrypted-intermediate-data.buffer.kb":"128","fs.client.resolve.remote.symlinks":"true","yarn.nodemanager.webapp.https.address":"0.0.0.0:8044","hadoop.http.cross-origin.allowed-origins":"*","mapreduce.job.encrypted-intermediate-data":"false","yarn.nodemanager.disk-health-checker.disk-utilization-threshold.enabled":"true","fs.s3a.executor.capacity":"16","yarn.timeline-service.entity-group-fs-store.retain-seconds":"604800","yarn.resourcemanager.metrics.runtime.buckets":"60,300,1440","yarn.timeline-service.generic-application-history.max-applications":"10000","yarn.nodemanager.local-dirs":"${hadoop.tmp.dir}/nm-local-dir","mapreduce.shuffle.connection-keep-alive.enable":"false","yarn.node-labels.configuration-type":"centralized","fs.s3a.path.style.access":"false","yarn.nodemanager.aux-services.mapreduce_shuffle.class":"org.apache.hadoop.mapred.ShuffleHandler","yarn.sharedcache.store.in-memory.staleness-period-mins":"10080","fs.adl.impl":"org.apache.hadoop.fs.adl.AdlFileSystem","yarn.resourcemanager.application.max-tags":"10","hadoop.domainname.resolver.impl":"org.apache.hadoop.net.DNSDomainNameResolver","yarn.resourcemanager.nodemanager.minimum.version":"NONE","mapreduce.jobhistory.webapp.xfs-filter.xframe-options":"SAMEORIGIN","yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled":"false","net.topology.impl":"org.apache.hadoop.net.NetworkTopology","io.map.index.skip":"0","yarn.timeline-service.reader.webapp.https.address":"${yarn.timeline-service.webapp.https.address}","fs.ftp.data.connection.mode":"ACTIVE_LOCAL_DATA_CONNECTION_MODE","mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed":"true","fs.azure.buffer.dir":"${hadoop.tmp.dir}/abfs","yarn.scheduler.maximum-allocation-vcores":"4","hadoop.http.cross-origin.allowed-headers":"X-Requested-With,Content-Type,Accept,Origin","yarn.nodemanager.log-aggregation.compression-type":"none","yarn.timeline-service.version":"1.0f","yarn.ipc.rpc.class":"org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC","mapreduce.reduce.maxattempts":"4","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size":"1000","hadoop.security.dns.log-slow-lookups.enabled":"false","mapreduce.job.committer.setup.cleanup.needed":"true","hadoop.security.secure.random.impl":"org.apache.hadoop.crypto.random.OpensslSecureRandom","mapreduce.job.running.reduce.limit":"0","fs.s3a.select.errors.include.sql":"false","fs.s3a.connection.request.timeout":"0","ipc.maximum.response.length":"134217728","yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.job.token.tracking.ids.enabled":"*********(redacted)","hadoop.caller.context.max.size":"128","yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed":"false","yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed":"false","hadoop.registry.system.acls":"sasl:yarn@, sasl:mapred@, sasl:hdfs@","yarn.nodemanager.recovery.dir":"${hadoop.tmp.dir}/yarn-nm-recovery","fs.s3a.fast.upload.buffer":"disk","mapreduce.jobhistory.intermediate-done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate","yarn.app.mapreduce.shuffle.log.separate":"true","yarn.log-aggregation.debug.filesize":"104857600","fs.s3a.max.total.tasks":"32","fs.s3a.readahead.range":"64K","hadoop.http.authentication.simple.anonymous.allowed":"true","fs.s3a.attempts.maximum":"20","hadoop.registry.zk.connection.timeout.ms":"15000","yarn.resourcemanager.delegation-token-renewer.thread-count":"*********(redacted)","yarn.resourcemanager.delegation-token-renewer.thread-timeout":"*********(redacted)","yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size":"10000","yarn.nodemanager.aux-services.manifest.reload-ms":"0","yarn.nodemanager.emit-container-events":"true","yarn.resourcemanager.resource-profiles.enabled":"false","yarn.timeline-service.hbase-schema.prefix":"prod.","fs.azure.authorization":"false","mapreduce.map.log.level":"INFO","ha.failover-controller.active-standby-elector.zk.op.retries":"3","yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs":"20","mapreduce.output.fileoutputformat.compress.type":"RECORD","yarn.resourcemanager.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/system/rmstore","yarn.timeline-service.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.ifile.readahead.bytes":"4194304","yarn.sharedcache.app-checker.class":"org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker","yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users":"true","yarn.nodemanager.resource.detect-hardware-capabilities":"false","mapreduce.cluster.acls.enabled":"false","mapreduce.job.speculative.retry-after-no-speculate":"1000","fs.viewfs.overload.scheme.target.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","hadoop.security.group.mapping.ldap.search.group.hierarchy.levels":"0","yarn.resourcemanager.fs.state-store.retry-interval-ms":"1000","file.stream-buffer-size":"4096","yarn.resourcemanager.application-timeouts.monitor.interval-ms":"3000","mapreduce.map.output.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","mapreduce.map.speculative":"true","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.hdfs-hash-file":"/runc-root/image-tag-to-hash","mapreduce.job.speculative.retry-after-speculate":"15000","yarn.nodemanager.linux-container-executor.cgroups.mount":"false","yarn.app.mapreduce.am.container.log.backups":"0","yarn.app.mapreduce.am.log.level":"INFO","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.ImageTagToManifestPlugin","io.bytes.per.checksum":"512","mapreduce.job.reduce.slowstart.completedmaps":"0.05","yarn.timeline-service.http-authentication.type":"simple","hadoop.security.group.mapping.ldap.search.attr.group.name":"cn","yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices":"auto","yarn.timeline-service.client.internal-timers-ttl-secs":"420","fs.s3a.select.output.csv.quote.character":"\"","hadoop.http.logs.enabled":"true","fs.s3a.block.size":"32M","yarn.sharedcache.client-server.address":"0.0.0.0:8045","yarn.nodemanager.logaggregation.threadpool-size-max":"100","yarn.resourcemanager.hostname":"0.0.0.0","yarn.resourcemanager.delegation.key.update-interval":"86400000","mapreduce.reduce.shuffle.fetch.retry.enabled":"${yarn.nodemanager.recovery.enabled}","mapreduce.map.memory.mb":"-1","mapreduce.task.skip.start.attempts":"2","fs.AbstractFileSystem.hdfs.impl":"org.apache.hadoop.fs.Hdfs","yarn.nodemanager.disk-health-checker.enable":"true","fs.s3a.select.output.csv.quote.fields":"always","ipc.client.tcpnodelay":"true","ipc.client.rpc-timeout.ms":"0","yarn.nodemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","yarn.resourcemanager.delegation-token-renewer.thread-retry-max-attempts":"*********(redacted)","ipc.client.low-latency":"false","mapreduce.input.lineinputformat.linespermap":"1","yarn.router.interceptor.user.threadpool-size":"5","ipc.client.connect.max.retries.on.timeouts":"45","yarn.timeline-service.leveldb-timeline-store.read-cache-size":"104857600","fs.AbstractFileSystem.har.impl":"org.apache.hadoop.fs.HarFs","mapreduce.job.split.metainfo.maxsize":"10000000","yarn.am.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.timeline-service.entity-group-fs-store.app-cache-size":"10","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-timeout-interval-secs":"360","fs.s3a.socket.recv.buffer":"8192","rpc.metrics.timeunit":"MILLISECONDS","yarn.resourcemanager.resource-tracker.address":"${yarn.resourcemanager.hostname}:8031","yarn.nodemanager.node-labels.provider.fetch-timeout-ms":"1200000","mapreduce.job.heap.memory-mb.ratio":"0.8","yarn.resourcemanager.leveldb-state-store.compaction-interval-secs":"3600","yarn.resourcemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","yarn.nodemanager.pluggable-device-framework.enabled":"false","yarn.scheduler.configuration.fs.path":"file://${hadoop.tmp.dir}/yarn/system/schedconf","mapreduce.client.output.filter":"FAILED","hadoop.http.filter.initializers":"org.apache.hadoop.http.lib.StaticUserWebFilter","mapreduce.reduce.memory.mb":"-1","yarn.timeline-service.hostname":"0.0.0.0","file.replication":"1","yarn.nodemanager.container-metrics.unregister-delay-ms":"10000","yarn.nodemanager.container-metrics.period-ms":"-1","mapreduce.fileoutputcommitter.task.cleanup.enabled":"false","yarn.nodemanager.log.retain-seconds":"10800","yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds":"3600","ipc.[port_number].callqueue.impl":"java.util.concurrent.LinkedBlockingQueue","yarn.resourcemanager.keytab":"/etc/krb5.keytab","hadoop.security.group.mapping.providers.combined":"true","mapreduce.reduce.merge.inmem.threshold":"1000","yarn.timeline-service.recovery.enabled":"false","fs.azure.saskey.usecontainersaskeyforallaccess":"true","yarn.sharedcache.nm.uploader.thread-count":"20","yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs":"3600","ipc.[port_number].weighted-cost.lockfree":"1","mapreduce.shuffle.ssl.enabled":"false","yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds":"259200000","yarn.nodemanager.opportunistic-containers-max-queue-length":"0","yarn.resourcemanager.state-store.max-completed-applications":"${yarn.resourcemanager.max-completed-applications}","mapreduce.job.speculative.minimum-allowed-tasks":"10","fs.s3a.aws.credentials.provider":"\n    org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider,\n    org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,\n    com.amazonaws.auth.EnvironmentVariableCredentialsProvider,\n    org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider\n  ","yarn.log-aggregation.retain-seconds":"-1","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb":"0","mapreduce.jobhistory.max-age-ms":"604800000","hadoop.http.cross-origin.allowed-methods":"GET,POST,HEAD","yarn.resourcemanager.opportunistic-container-allocation.enabled":"false","mapreduce.jobhistory.webapp.address":"0.0.0.0:19888","hadoop.system.tags":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.log-aggregation.file-controller.TFile.class":"org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController","yarn.client.nodemanager-connect.max-wait-ms":"180000","yarn.resourcemanager.webapp.address":"${yarn.resourcemanager.hostname}:8088","mapreduce.jobhistory.recovery.enable":"false","mapreduce.reduce.shuffle.parallelcopies":"5","fs.AbstractFileSystem.webhdfs.impl":"org.apache.hadoop.fs.WebHdfs","fs.trash.interval":"0","yarn.app.mapreduce.client.max-retries":"3","hadoop.security.authentication":"simple","mapreduce.task.profile.reduce.params":"${mapreduce.task.profile.params}","yarn.app.mapreduce.am.resource.mb":"1536","mapreduce.input.fileinputformat.list-status.num-threads":"1","yarn.nodemanager.container-executor.class":"org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor","io.mapfile.bloom.size":"1048576","yarn.timeline-service.ttl-ms":"604800000","yarn.resourcemanager.nm-container-queuing.min-queue-length":"5","yarn.nodemanager.resource.cpu-vcores":"-1","mapreduce.job.reduces":"1","fs.s3a.multipart.size":"64M","fs.s3a.select.input.csv.comment.marker":"#","yarn.scheduler.minimum-allocation-vcores":"1","mapreduce.job.speculative.speculative-cap-total-tasks":"0.01","hadoop.ssl.client.conf":"ssl-client.xml","mapreduce.job.queuename":"default","mapreduce.job.encrypted-intermediate-data-key-size-bits":"128","fs.s3a.metadatastore.authoritative":"false","ipc.[port_number].weighted-cost.response":"1","yarn.nodemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","ha.health-monitor.sleep-after-disconnect.ms":"1000","yarn.app.mapreduce.shuffle.log.limit.kb":"0","hadoop.security.group.mapping":"org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback","yarn.client.application-client-protocol.poll-timeout-ms":"-1","mapreduce.jobhistory.jhist.format":"binary","mapreduce.task.stuck.timeout-ms":"600000","yarn.resourcemanager.application.max-tag.length":"100","yarn.resourcemanager.ha.enabled":"false","dfs.client.ignore.namenode.default.kms.uri":"false","hadoop.http.staticuser.user":"dr.who","mapreduce.task.exit.timeout.check-interval-ms":"20000","mapreduce.jobhistory.intermediate-user-done-dir.permissions":"770","mapreduce.task.exit.timeout":"60000","yarn.nodemanager.linux-container-executor.resources-handler.class":"org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler","mapreduce.reduce.shuffle.memory.limit.percent":"0.25","yarn.resourcemanager.reservation-system.enable":"false","mapreduce.map.output.compress":"false","ha.zookeeper.acl":"world:anyone:rwcda","ipc.server.max.connections":"0","yarn.nodemanager.runtime.linux.docker.default-container-network":"host","yarn.router.webapp.address":"0.0.0.0:8089","yarn.scheduler.maximum-allocation-mb":"8192","yarn.resourcemanager.scheduler.monitor.policies":"org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy","yarn.sharedcache.cleaner.period-mins":"1440","yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint":"http://localhost:3476/v1.0/docker/cli","yarn.app.mapreduce.am.container.log.limit.kb":"0","ipc.client.connect.retry.interval":"1000","yarn.timeline-service.http-cross-origin.enabled":"false","fs.wasbs.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure","yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms":"1000","yarn.federation.subcluster-resolver.class":"org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl","yarn.resourcemanager.zk-state-store.parent-path":"/rmstore","fs.s3a.select.input.csv.field.delimiter":",","mapreduce.jobhistory.cleaner.enable":"true","yarn.timeline-service.client.fd-flush-interval-secs":"10","hadoop.security.kms.client.encrypted.key.cache.expiry":"43200000","yarn.client.nodemanager-client-async.thread-pool-max-size":"500","mapreduce.map.maxattempts":"4","yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms":"1000","fs.s3a.committer.staging.tmp.path":"tmp/staging","yarn.nodemanager.sleep-delay-before-sigkill.ms":"250","yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms":"10","mapreduce.job.end-notification.retry.attempts":"0","yarn.nodemanager.resource.count-logical-processors-as-cores":"false","hadoop.registry.zk.root":"/registry","adl.feature.ownerandgroup.enableupn":"false","yarn.resourcemanager.zk-max-znode-size.bytes":"1048576","mapreduce.job.reduce.shuffle.consumer.plugin.class":"org.apache.hadoop.mapreduce.task.reduce.Shuffle","yarn.resourcemanager.delayed.delegation-token.removal-interval-ms":"*********(redacted)","yarn.nodemanager.localizer.cache.target-size-mb":"10240","fs.s3a.committer.staging.conflict-mode":"append","mapreduce.client.libjars.wildcard":"true","fs.s3a.committer.staging.unique-filenames":"true","yarn.nodemanager.node-attributes.provider.fetch-timeout-ms":"1200000","fs.s3a.list.version":"2","ftp.client-write-packet-size":"65536","ipc.[port_number].weighted-cost.lockexclusive":"100","fs.AbstractFileSystem.adl.impl":"org.apache.hadoop.fs.adl.Adl","yarn.nodemanager.container-log-monitor.enable":"false","hadoop.security.key.default.cipher":"AES/CTR/NoPadding","yarn.client.failover-retries":"0","fs.s3a.multipart.purge.age":"86400","mapreduce.job.local-fs.single-disk-limit.check.interval-ms":"5000","net.topology.node.switch.mapping.impl":"org.apache.hadoop.net.ScriptBasedMapping","yarn.nodemanager.amrmproxy.address":"0.0.0.0:8049","ipc.server.listen.queue.size":"256","ipc.[port_number].decay-scheduler.period-ms":"5000","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.cache-refresh-interval-secs":"60","map.sort.class":"org.apache.hadoop.util.QuickSort","fs.viewfs.rename.strategy":"SAME_MOUNTPOINT","hadoop.security.kms.client.authentication.retry-count":"1","fs.permissions.umask-mode":"022","fs.s3a.assumed.role.credentials.provider":"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider","yarn.nodemanager.runtime.linux.runc.privileged-containers.allowed":"false","yarn.nodemanager.vmem-check-enabled":"true","yarn.nodemanager.numa-awareness.enabled":"false","yarn.nodemanager.recovery.compaction-interval-secs":"3600","yarn.app.mapreduce.client-am.ipc.max-retries":"3","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds":"60","yarn.federation.registry.base-dir":"yarnfederation/","yarn.nodemanager.health-checker.run-before-startup":"false","mapreduce.job.max.map":"-1","mapreduce.job.local-fs.single-disk-limit.bytes":"-1","mapreduce.shuffle.pathcache.concurrency-level":"16","mapreduce.job.ubertask.maxreduces":"1","mapreduce.shuffle.pathcache.max-weight":"10485760","hadoop.security.kms.client.encrypted.key.cache.size":"500","hadoop.security.java.secure.random.algorithm":"SHA1PRNG","ha.failover-controller.cli-check.rpc-timeout.ms":"20000","mapreduce.jobhistory.jobname.limit":"50","fs.s3a.select.input.compression":"none","yarn.client.nodemanager-connect.retry-interval-ms":"10000","ipc.[port_number].scheduler.priority.levels":"4","yarn.timeline-service.state-store-class":"org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore","yarn.nodemanager.env-whitelist":"JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ","yarn.sharedcache.nested-level":"3","yarn.timeline-service.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","fs.azure.user.agent.prefix":"unknown","yarn.resourcemanager.zk-delegation-token-node.split-index":"*********(redacted)","yarn.nodemanager.numa-awareness.read-topology":"false","yarn.nodemanager.webapp.address":"${yarn.nodemanager.hostname}:8042","rpc.metrics.quantile.enable":"false","yarn.registry.class":"org.apache.hadoop.registry.client.impl.FSRegistryOperationsService","mapreduce.jobhistory.admin.acl":"*","yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size":"10","yarn.scheduler.queue-placement-rules":"user-group","hadoop.http.authentication.kerberos.keytab":"${user.home}/hadoop.keytab","yarn.resourcemanager.recovery.enabled":"false","fs.s3a.select.input.csv.header":"none","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-size":"500","yarn.timeline-service.webapp.rest-csrf.enabled":"false","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb":"0"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.maintenance.version":"3","java.specification.version":"11","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Ubuntu","java.vm.specification.version":"11","user.home":"/home/jovyan","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-11-openjdk-amd64/lib","user.dir":"/home/jovyan/work","java.library.path":"/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"11.0.28+6-post-Ubuntu-1ubuntu122.04.1","jetty.git.hash":"abdcda73818a1a2c705da276edb0bf6581e7997e","java.runtime.version":"11.0.28+6-post-Ubuntu-1ubuntu122.04.1","java.vm.info":"mixed mode, sharing","java.runtime.name":"OpenJDK Runtime Environment","java.version.date":"2025-07-15","file.separator":"/","java.class.version":"55.0","java.specification.name":"Java Platform API Specification","file.encoding":"UTF-8","jdk.reflect.useDirectMethodHandle":"false","user.timezone":"GMT","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","java.vm.compressedOopsMode":"32-bit","os.version":"6.12.38+kali-amd64","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"https://ubuntu.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Ubuntu","jdk.debug":"release","java.vendor.url.bug":"https://bugs.launchpad.net/ubuntu/+source/openjdk-lts","user.name":"jovyan","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"org.apache.spark.deploy.SparkSubmit --master spark://spark-master:7077 --conf spark.master=spark://spark-master:7077 --conf spark.jars.packages=org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=/tmp/spark-events --conf spark.app.name=KafkaTestStreaming --conf spark.ui.port=4040 --conf spark.sql.streaming.checkpointLocation=/tmp/checkpoint pyspark-shell","java.home":"/usr/lib/jvm/java-11-openjdk-amd64","java.version":"11.0.28","sun.io.unicode.encoding":"UnicodeLittle"},"Metrics Properties":{"*.sink.servlet.class":"org.apache.spark.metrics.sink.MetricsServlet","*.sink.servlet.path":"/metrics/json","applications.sink.servlet.path":"/metrics/applications/json","master.sink.servlet.path":"/metrics/master/json"},"Classpath Entries":{"/opt/conda/lib/python3.11/site-packages/pyspark/jars/annotations-17.0.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kryo-shaded-4.0.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hadoop-client-api-3.3.4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/datanucleus-rdbms-4.1.19.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/activation-1.1.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/json4s-ast_2.12-3.7.0-M11.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-batch-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hk2-utils-2.6.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/libthrift-0.12.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/paranamer-2.8.jar":"System Classpath","spark://306c10bfc250:33843/jars/org.lz4_lz4-java-1.8.0.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-graphx_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/super-csv-2.2.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-logging-1.1.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jsr305-3.0.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jaxb-runtime-2.3.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-lang3-3.12.0.jar":"System Classpath","spark://306c10bfc250:33843/jars/org.apache.kafka_kafka-clients-3.4.1.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-mesos_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jodd-core-3.5.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-kubernetes_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jackson-datatype-jsr310-2.15.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/httpclient-4.5.14.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-metrics-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-common-utils_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-policy-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jcl-over-slf4j-2.0.7.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-core-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-unsafe_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/joda-time-2.12.5.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/metrics-graphite-4.2.19.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-apps-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/transaction-api-1.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/scala-library-2.12.18.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/parquet-common-1.13.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/okhttp-3.12.12.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/parquet-column-1.13.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/snakeyaml-2.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/orc-shims-1.9.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/tink-1.9.0.jar":"System Classpath","spark://306c10bfc250:33843/files/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/zstd-jni-1.5.5-4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/mesos-1.4.3-shaded-protobuf.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jersey-client-2.40.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/scala-xml_2.12-2.1.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-collections4-4.4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-node-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-mllib-local_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/chill-java-0.10.0.jar":"System Classpath","spark://306c10bfc250:33843/files/commons-logging_commons-logging-1.1.3.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-compress-1.23.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jakarta.ws.rs-api-2.1.6.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-crypto-1.1.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jakarta.xml.bind-api-2.3.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/javassist-3.29.2-GA.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-rbac-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/json-1.8.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/pickle-1.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/cats-kernel_2.12-2.1.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jta-1.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-all-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jersey-container-servlet-core-2.40.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jackson-module-scala_2.12-2.15.2.jar":"System Classpath","spark://306c10bfc250:33843/files/com.google.code.findbugs_jsr305-3.0.0.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/json4s-core_2.12-3.7.0-M11.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/stream-2.9.6.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/univocity-parsers-2.9.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/json4s-scalap_2.12-3.7.0-M11.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jackson-dataformat-yaml-2.15.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/scala-compiler-2.12.18.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-lang-2.6.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/parquet-encoding-1.13.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hadoop-client-runtime-3.3.4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jackson-core-asl-1.9.13.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spire-util_2.12-0.17.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-transport-classes-epoll-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-codec-socks-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-exec-2.3.9-core.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-streaming_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/log4j-core-2.20.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-beeline-2.3.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/leveldbjni-all-1.8.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jul-to-slf4j-2.0.7.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/aircompressor-0.26.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-launcher_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jackson-databind-2.15.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-math3-3.6.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/chill_2.12-0.10.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/metrics-jmx-4.2.19.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-kvstore_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-network-common_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hadoop-shaded-guava-1.1.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/avro-ipc-1.11.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/json4s-jackson_2.12-3.7.0-M11.jar":"System Classpath","spark://306c10bfc250:33843/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/log4j-slf4j2-impl-2.20.0.jar":"System Classpath","spark://306c10bfc250:33843/files/org.apache.commons_commons-pool2-2.11.1.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/log4j-1.2-api-2.20.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/snakeyaml-engine-2.6.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/oro-2.0.8.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-serde-2.3.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/lapack-3.0.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/curator-framework-2.13.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-resolver-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/scala-reflect-2.12.18.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/slf4j-api-2.0.7.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/arrow-memory-netty-12.0.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/xbean-asm9-shaded-4.23.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/JTransforms-3.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-pool-1.5.4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-coordination-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/orc-core-1.9.2-shaded-protobuf.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hk2-locator-2.6.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-cli-1.5.0.jar":"System Classpath","spark://306c10bfc250:33843/jars/org.slf4j_slf4j-api-2.0.7.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-certificates-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-cli-2.3.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-events-6.7.2.jar":"System Classpath","spark://306c10bfc250:33843/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-resource-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jackson-core-2.15.2.jar":"System Classpath","spark://306c10bfc250:33843/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/compress-lzf-1.1.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/audience-annotations-0.5.0.jar":"System Classpath","spark://306c10bfc250:33843/files/org.xerial.snappy_snappy-java-1.1.10.3.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-tags_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/minlog-1.3.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/parquet-format-structures-1.13.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jackson-mapper-asl-1.9.13.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-sketch_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/curator-client-2.13.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-flowcontrol-6.7.2.jar":"System Classpath","spark://306c10bfc250:33843/jars/com.google.code.findbugs_jsr305-3.0.0.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/avro-1.11.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-shims-common-2.3.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/arpack_combined_all-0.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/arrow-memory-core-12.0.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/avro-mapred-1.11.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-autoscaling-6.7.2.jar":"System Classpath","spark://306c10bfc250:33843/files/org.apache.hadoop_hadoop-client-api-3.3.4.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/datanucleus-api-jdo-4.2.4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/ST4-4.0.4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-common-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/orc-mapreduce-1.9.2-shaded-protobuf.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jakarta.servlet-api-4.0.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-handler-proxy-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/zjsonpatch-0.3.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-compiler-3.1.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/parquet-hadoop-1.13.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/metrics-json-4.2.19.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-yarn_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/opencsv-2.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jdo-api-3.0.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-client-api-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-collections-3.2.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-extensions-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-metastore-2.3.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/scala-parser-combinators_2.12-2.3.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-codec-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/zookeeper-jute-3.6.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/okio-1.15.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jakarta.annotation-api-1.3.5.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-shims-scheduler-2.3.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-text-1.10.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/libfb303-0.9.3.jar":"System Classpath","spark://306c10bfc250:33843/files/org.slf4j_slf4j-api-2.0.7.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jakarta.inject-2.6.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-networking-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/arrow-format-12.0.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/parquet-jackson-1.13.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/xz-1.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/janino-3.1.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/antlr4-runtime-4.9.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-buffer-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-storage-api-2.8.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-handler-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/JLargeArrays-1.5.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/breeze_2.12-2.1.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-codec-http-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-sql-api_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/guava-14.0.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-shims-2.3.9.jar":"System Classpath","spark://306c10bfc250:33843/files/org.lz4_lz4-java-1.8.0.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/antlr-runtime-3.5.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-storageclass-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-client-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-unix-common-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/metrics-jvm-4.2.19.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-codec-http2-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/arpack-3.0.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-scheduling-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jersey-common-2.40.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/javolution-5.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jpam-1.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-io-2.13.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/breeze-macros_2.12-2.1.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jersey-hk2-2.40.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/stax-api-1.0.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/gson-2.2.4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/scala-collection-compat_2.12-2.7.0.jar":"System Classpath","spark://306c10bfc250:33843/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-jdbc-2.3.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/logging-interceptor-3.12.12.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-hive-thriftserver_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/derby-10.14.2.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hadoop-yarn-server-web-proxy-3.3.4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-llap-common-2.3.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-transport-classes-kqueue-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-gatewayapi-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jline-2.14.6.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/rocksdbjni-8.3.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/snappy-java-1.1.10.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spire_2.12-0.17.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jakarta.validation-api-2.0.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/RoaringBitmap-0.9.45.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jersey-container-servlet-2.40.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/javax.jdo-3.2.0-m3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/datasketches-memory-2.1.0.jar":"System Classpath","spark://306c10bfc250:33843/jars/org.apache.commons_commons-pool2-2.11.1.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/curator-recipes-2.13.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/blas-3.0.3.jar":"System Classpath","spark://306c10bfc250:33843/jars/commons-logging_commons-logging-1.1.3.jar":"Added By User","spark://306c10bfc250:33843/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-apiextensions-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-admissionregistration-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-discovery-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-mllib_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-catalyst_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/osgi-resource-locator-1.0.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-dbcp-1.4.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-hive_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/istack-commons-runtime-3.0.8.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/shims-0.9.45.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jersey-server-2.40.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hk2-api-2.6.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/datasketches-java-3.3.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-repl_2.12-3.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-transport-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/zookeeper-3.6.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/bonecp-0.8.0.RELEASE.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/commons-codec-1.16.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/log4j-api-2.20.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-shims-0.23-2.3.9.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/flatbuffers-java-1.12.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/py4j-0.10.9.7.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/HikariCP-2.5.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/aopalliance-repackaged-2.6.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spire-macros_2.12-0.17.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-sql_2.12-3.5.1.jar":"System Classpath","spark://306c10bfc250:33843/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/algebra_2.12-2.0.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-service-rpc-3.1.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/lz4-java-1.8.0.jar":"System Classpath","spark://306c10bfc250:33843/files/org.apache.kafka_kafka-clients-3.4.1.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/httpcore-4.4.16.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/metrics-core-4.2.19.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/conf":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/arrow-vector-12.0.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/jackson-annotations-2.15.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/objenesis-3.3.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spire-platform_2.12-0.17.0.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/netty-common-4.1.96.Final.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/kubernetes-httpclient-okhttp-6.7.2.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/threeten-extra-1.7.1.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/datanucleus-core-4.1.17.jar":"System Classpath","/opt/conda/lib/python3.11/site-packages/pyspark/jars/hive-common-2.3.9.jar":"System Classpath","spark://306c10bfc250:33843/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar":"Added By User","/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-network-shuffle_2.12-3.5.1.jar":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"KafkaTestStreaming","App ID":"app-20250928160659-0004","Timestamp":1759075618190,"User":"jovyan"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1759075622473,"Executor ID":"0","Executor Info":{"Host":"172.18.0.8","Total Cores":2,"Log Urls":{"stdout":"http://172.18.0.8:8081/logPage/?appId=app-20250928160659-0004&executorId=0&logType=stdout","stderr":"http://172.18.0.8:8081/logPage/?appId=app-20250928160659-0004&executorId=0&logType=stderr"},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1759075622473}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1759075622487,"Executor ID":"1","Executor Info":{"Host":"172.18.0.2","Total Cores":2,"Log Urls":{"stdout":"http://172.18.0.2:8081/logPage/?appId=app-20250928160659-0004&executorId=1&logType=stdout","stderr":"http://172.18.0.2:8081/logPage/?appId=app-20250928160659-0004&executorId=1&logType=stderr"},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1759075622487}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"172.18.0.8","Port":45259},"Maximum Memory":455501414,"Timestamp":1759075622589,"Maximum Onheap Memory":455501414,"Maximum Offheap Memory":0}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"1","Host":"172.18.0.2","Port":33449},"Maximum Memory":455501414,"Timestamp":1759075622595,"Maximum Onheap Memory":455501414,"Maximum Offheap Memory":0}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","name":null,"timestamp":"2025-09-28T16:07:03.370Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":0,"rootExecutionId":0,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@738e039c\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4135949c","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":3,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":4,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075624680,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":1,"rootExecutionId":0,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@3e332a72\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4135949c","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":3,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":4,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075624697,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":1,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1759075625115,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":3,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[0],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"1","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"0","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":3,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075625134,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"1","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"0","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075625273,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075625273,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075625634,"Failed":false,"Killed":false,"Accumulables":[{"ID":5,"Name":"internal.metrics.executorDeserializeTime","Update":251,"Value":251,"Internal":true,"Count Failed Values":true},{"ID":6,"Name":"internal.metrics.executorDeserializeCpuTime","Update":187477632,"Value":187477632,"Internal":true,"Count Failed Values":true},{"ID":7,"Name":"internal.metrics.executorRunTime","Update":30,"Value":30,"Internal":true,"Count Failed Values":true},{"ID":8,"Name":"internal.metrics.executorCpuTime","Update":27274233,"Value":27274233,"Internal":true,"Count Failed Values":true},{"ID":9,"Name":"internal.metrics.resultSize","Update":1295,"Value":1295,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.jvmGCTime","Update":10,"Value":10,"Internal":true,"Count Failed Values":true},{"ID":11,"Name":"internal.metrics.resultSerializationTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":251,"Executor Deserialize CPU Time":187477632,"Executor Run Time":30,"Executor CPU Time":27274233,"Peak Execution Memory":0,"Result Size":1295,"JVM GC Time":10,"Result Serialization Time":2,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":3,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075625134,"Completion Time":1759075625641,"Accumulables":[{"ID":5,"Name":"internal.metrics.executorDeserializeTime","Value":251,"Internal":true,"Count Failed Values":true},{"ID":6,"Name":"internal.metrics.executorDeserializeCpuTime","Value":187477632,"Internal":true,"Count Failed Values":true},{"ID":7,"Name":"internal.metrics.executorRunTime","Value":30,"Internal":true,"Count Failed Values":true},{"ID":8,"Name":"internal.metrics.executorCpuTime","Value":27274233,"Internal":true,"Count Failed Values":true},{"ID":9,"Name":"internal.metrics.resultSize","Value":1295,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.jvmGCTime","Value":10,"Internal":true,"Count Failed Values":true},{"ID":11,"Name":"internal.metrics.resultSerializationTime","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1759075625643,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":2,"rootExecutionId":0,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#28]\nArguments: <empty>, [toprettystring(value)#28]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan <empty>, [toprettystring(value)#28]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":40,"metricType":"sum"}]},"time":1759075625692,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":2,"accumUpdates":[[40,0]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":2,"time":1759075625699,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":1,"time":1759075625705,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":0,"time":1759075625706,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","name":null,"timestamp":"2025-09-28T16:07:03.407Z","batchId":0,"batchDuration":2322,"durationMs":{"triggerExecution":2322,"queryPlanning":471,"getBatch":43,"commitOffsets":22,"latestOffset":661,"addBatch":1067,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":null,"endOffset":"{\"test-topic\":{\"0\":30}}","latestOffset":"{\"test-topic\":{\"0\":30}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":0,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:07:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:07:40.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:08:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","name":null,"timestamp":"2025-09-28T16:08:03.938Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":3,"rootExecutionId":3,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@680557f2\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5aa54861","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":42,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":43,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":44,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":41,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075684043,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":4,"rootExecutionId":3,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@37f8efb3\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5aa54861","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":42,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":43,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":44,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":41,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075684052,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":4,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1759075684064,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"10\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[1],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"4","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"3","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"10\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075684066,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"4","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"3","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075684072,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075684072,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075684102,"Failed":false,"Killed":false,"Accumulables":[{"ID":45,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":46,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8535829,"Value":8535829,"Internal":true,"Count Failed Values":true},{"ID":47,"Name":"internal.metrics.executorRunTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":48,"Name":"internal.metrics.executorCpuTime","Update":1807025,"Value":1807025,"Internal":true,"Count Failed Values":true},{"ID":49,"Name":"internal.metrics.resultSize","Update":1209,"Value":1209,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":8535829,"Executor Run Time":1,"Executor CPU Time":1807025,"Peak Execution Memory":0,"Result Size":1209,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"10\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075684066,"Completion Time":1759075684103,"Accumulables":[{"ID":45,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":46,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8535829,"Internal":true,"Count Failed Values":true},{"ID":47,"Name":"internal.metrics.executorRunTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":48,"Name":"internal.metrics.executorCpuTime","Value":1807025,"Internal":true,"Count Failed Values":true},{"ID":49,"Name":"internal.metrics.resultSize","Value":1209,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1759075684103,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":5,"rootExecutionId":3,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#60]\nArguments: <empty>, [toprettystring(value)#60]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan <empty>, [toprettystring(value)#60]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":80,"metricType":"sum"}]},"time":1759075684125,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":5,"accumUpdates":[[80,0]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":5,"time":1759075684130,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":4,"time":1759075684131,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":3,"time":1759075684131,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","name":null,"timestamp":"2025-09-28T16:08:03.941Z","batchId":0,"batchDuration":211,"durationMs":{"triggerExecution":211,"queryPlanning":17,"getBatch":3,"commitOffsets":21,"latestOffset":44,"addBatch":100,"walCommit":25},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":null,"endOffset":"{\"test-topic\":{\"0\":40}}","latestOffset":"{\"test-topic\":{\"0\":40}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":0,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":6,"rootExecutionId":6,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@174fd9f6\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@25fdfaae","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":82,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":83,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":84,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":81,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075690069,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":7,"rootExecutionId":6,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@28805e79\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@25fdfaae","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":82,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":83,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":84,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":81,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075690077,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":7,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":2,"Submission Time":1759075690099,"Stage Infos":[{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"DataSourceRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[2],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"7","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"6","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"DataSourceRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075690102,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"7","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"6","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075690113,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075690113,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075691671,"Failed":false,"Killed":false,"Accumulables":[{"ID":81,"Name":"duration","Update":"1228","Value":"1228","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":82,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":85,"Name":"internal.metrics.executorDeserializeTime","Update":88,"Value":88,"Internal":true,"Count Failed Values":true},{"ID":86,"Name":"internal.metrics.executorDeserializeCpuTime","Update":70822572,"Value":70822572,"Internal":true,"Count Failed Values":true},{"ID":87,"Name":"internal.metrics.executorRunTime","Update":1455,"Value":1455,"Internal":true,"Count Failed Values":true},{"ID":88,"Name":"internal.metrics.executorCpuTime","Update":842939451,"Value":842939451,"Internal":true,"Count Failed Values":true},{"ID":89,"Name":"internal.metrics.resultSize","Update":2587,"Value":2587,"Internal":true,"Count Failed Values":true},{"ID":90,"Name":"internal.metrics.jvmGCTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":117,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":127367744,"JVMOffHeapMemory":70491280,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":19603,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":19603,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16796774,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":4,"MinorGCTime":38,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":38},"Task Metrics":{"Executor Deserialize Time":88,"Executor Deserialize CPU Time":70822572,"Executor Run Time":1455,"Executor CPU Time":842939451,"Peak Execution Memory":0,"Result Size":2587,"JVM GC Time":6,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"DataSourceRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075690102,"Completion Time":1759075691672,"Accumulables":[{"ID":81,"Name":"duration","Value":"1228","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":82,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":85,"Name":"internal.metrics.executorDeserializeTime","Value":88,"Internal":true,"Count Failed Values":true},{"ID":86,"Name":"internal.metrics.executorDeserializeCpuTime","Value":70822572,"Internal":true,"Count Failed Values":true},{"ID":87,"Name":"internal.metrics.executorRunTime","Value":1455,"Internal":true,"Count Failed Values":true},{"ID":88,"Name":"internal.metrics.executorCpuTime","Value":842939451,"Internal":true,"Count Failed Values":true},{"ID":89,"Name":"internal.metrics.resultSize","Value":2587,"Internal":true,"Count Failed Values":true},{"ID":90,"Name":"internal.metrics.jvmGCTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":117,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":2,"Completion Time":1759075691672,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":8,"rootExecutionId":6,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#68]\nArguments: [toprettystring(value)#68]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#68]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":120,"metricType":"sum"}]},"time":1759075691694,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":8,"accumUpdates":[[120,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":8,"time":1759075692364,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":7,"time":1759075692365,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":6,"time":1759075692365,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","name":null,"timestamp":"2025-09-28T16:08:10.000Z","batchId":1,"batchDuration":2380,"durationMs":{"triggerExecution":2380,"queryPlanning":11,"getBatch":0,"commitOffsets":15,"latestOffset":10,"addBatch":2303,"walCommit":38},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":30}}","endOffset":"{\"test-topic\":{\"0\":40}}","latestOffset":"{\"test-topic\":{\"0\":40}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":4.201680672268908,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:08:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:08:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:08:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:08:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:08:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:08:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:09:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:09:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:09:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:09:20.000Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":9,"rootExecutionId":9,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@61ce1a7a\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@14c6b184","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":123,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":124,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":125,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":121,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075770061,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":10,"rootExecutionId":10,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@18cd4d61\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4b80e49a","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":126,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":127,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":128,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":122,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075770061,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":11,"rootExecutionId":9,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@607f15c3\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@14c6b184","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":123,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":124,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":125,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":121,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075770069,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":12,"rootExecutionId":10,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@b78e2d4\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4b80e49a","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":126,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":127,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":128,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":122,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075770071,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":11,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":3,"Submission Time":1759075770078,"Stage Infos":[{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"19\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"DataSourceRDD","Scope":"{\"id\":\"22\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[3],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"11","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"9","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":12,"accumUpdates":[]}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"19\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"DataSourceRDD","Scope":"{\"id\":\"22\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075770079,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"11","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"9","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerJobStart","Job ID":4,"Submission Time":1759075770087,"Stage Infos":[{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"23\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"26\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"DataSourceRDD","Scope":"{\"id\":\"26\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[4],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"12","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"10","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"23\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"26\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"DataSourceRDD","Scope":"{\"id\":\"26\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075770088,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"12","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"10","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075770086,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075770094,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075770086,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075770652,"Failed":false,"Killed":false,"Accumulables":[{"ID":121,"Name":"duration","Update":"530","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":123,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":129,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9696823,"Value":9696823,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.executorRunTime","Update":534,"Value":534,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.executorCpuTime","Update":31563223,"Value":31563223,"Internal":true,"Count Failed Values":true},{"ID":133,"Name":"internal.metrics.resultSize","Update":2544,"Value":2544,"Internal":true,"Count Failed Values":true},{"ID":135,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":161,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":9696823,"Executor Run Time":534,"Executor CPU Time":31563223,"Peak Execution Memory":0,"Result Size":2544,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"19\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"DataSourceRDD","Scope":"{\"id\":\"22\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075770079,"Completion Time":1759075770653,"Accumulables":[{"ID":121,"Name":"duration","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":123,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":129,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9696823,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.executorRunTime","Value":534,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.executorCpuTime","Value":31563223,"Internal":true,"Count Failed Values":true},{"ID":133,"Name":"internal.metrics.resultSize","Value":2544,"Internal":true,"Count Failed Values":true},{"ID":135,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":161,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":3,"Completion Time":1759075770653,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075770094,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075770659,"Failed":false,"Killed":false,"Accumulables":[{"ID":122,"Name":"duration","Update":"538","Value":"538","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":126,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":164,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":165,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8157781,"Value":8157781,"Internal":true,"Count Failed Values":true},{"ID":166,"Name":"internal.metrics.executorRunTime","Update":540,"Value":540,"Internal":true,"Count Failed Values":true},{"ID":167,"Name":"internal.metrics.executorCpuTime","Update":35928405,"Value":35928405,"Internal":true,"Count Failed Values":true},{"ID":168,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":196,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":8157781,"Executor Run Time":540,"Executor CPU Time":35928405,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"23\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"26\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"DataSourceRDD","Scope":"{\"id\":\"26\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075770088,"Completion Time":1759075770659,"Accumulables":[{"ID":122,"Name":"duration","Value":"538","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":126,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":164,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":165,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8157781,"Internal":true,"Count Failed Values":true},{"ID":166,"Name":"internal.metrics.executorRunTime","Value":540,"Internal":true,"Count Failed Values":true},{"ID":167,"Name":"internal.metrics.executorCpuTime","Value":35928405,"Internal":true,"Count Failed Values":true},{"ID":168,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":196,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":4,"Completion Time":1759075770660,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":13,"rootExecutionId":9,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#78]\nArguments: [toprettystring(value)#78]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#78]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":199,"metricType":"sum"}]},"time":1759075770670,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":14,"rootExecutionId":10,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#82]\nArguments: [toprettystring(value)#82]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#82]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":200,"metricType":"sum"}]},"time":1759075770674,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":13,"accumUpdates":[[199,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":13,"time":1759075770675,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":11,"time":1759075770676,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":9,"time":1759075770676,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":14,"accumUpdates":[[200,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":14,"time":1759075770679,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":12,"time":1759075770680,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":10,"time":1759075770680,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","name":null,"timestamp":"2025-09-28T16:09:30.000Z","batchId":2,"batchDuration":698,"durationMs":{"triggerExecution":698,"queryPlanning":12,"getBatch":0,"commitOffsets":22,"latestOffset":12,"addBatch":624,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":40}}","endOffset":"{\"test-topic\":{\"0\":50}}","latestOffset":"{\"test-topic\":{\"0\":50}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":14.326647564469916,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","name":null,"timestamp":"2025-09-28T16:09:30.000Z","batchId":1,"batchDuration":700,"durationMs":{"triggerExecution":700,"queryPlanning":12,"getBatch":0,"commitOffsets":20,"latestOffset":11,"addBatch":628,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":40}}","endOffset":"{\"test-topic\":{\"0\":50}}","latestOffset":"{\"test-topic\":{\"0\":50}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":14.285714285714286,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:09:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:09:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:10:00.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:10:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:10:10.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:10:30.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:10:30.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:10:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:10:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","name":null,"timestamp":"2025-09-28T16:10:44.451Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":15,"rootExecutionId":15,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2256ee25\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2e6fd233","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":202,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":203,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":204,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":201,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075844543,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":16,"rootExecutionId":15,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@40988ff0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2e6fd233","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":202,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":203,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":204,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":201,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075844549,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":16,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":5,"Submission Time":1759075844558,"Stage Infos":[{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"37\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[5],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"16","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"15","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"37\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075844558,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"16","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"15","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075844564,"Executor ID":"0","Host":"172.18.0.8","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075844564,"Executor ID":"0","Host":"172.18.0.8","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075844794,"Failed":false,"Killed":false,"Accumulables":[{"ID":205,"Name":"internal.metrics.executorDeserializeTime","Update":180,"Value":180,"Internal":true,"Count Failed Values":true},{"ID":206,"Name":"internal.metrics.executorDeserializeCpuTime","Update":150618764,"Value":150618764,"Internal":true,"Count Failed Values":true},{"ID":207,"Name":"internal.metrics.executorRunTime","Update":23,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":208,"Name":"internal.metrics.executorCpuTime","Update":22991673,"Value":22991673,"Internal":true,"Count Failed Values":true},{"ID":209,"Name":"internal.metrics.resultSize","Update":1295,"Value":1295,"Internal":true,"Count Failed Values":true},{"ID":210,"Name":"internal.metrics.jvmGCTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":211,"Name":"internal.metrics.resultSerializationTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":180,"Executor Deserialize CPU Time":150618764,"Executor Run Time":23,"Executor CPU Time":22991673,"Peak Execution Memory":0,"Result Size":1295,"JVM GC Time":7,"Result Serialization Time":2,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"37\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075844558,"Completion Time":1759075844795,"Accumulables":[{"ID":205,"Name":"internal.metrics.executorDeserializeTime","Value":180,"Internal":true,"Count Failed Values":true},{"ID":206,"Name":"internal.metrics.executorDeserializeCpuTime","Value":150618764,"Internal":true,"Count Failed Values":true},{"ID":207,"Name":"internal.metrics.executorRunTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":208,"Name":"internal.metrics.executorCpuTime","Value":22991673,"Internal":true,"Count Failed Values":true},{"ID":209,"Name":"internal.metrics.resultSize","Value":1295,"Internal":true,"Count Failed Values":true},{"ID":210,"Name":"internal.metrics.jvmGCTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":211,"Name":"internal.metrics.resultSerializationTime","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":5,"Completion Time":1759075844795,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":17,"rootExecutionId":15,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#116]\nArguments: <empty>, [toprettystring(value)#116]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan <empty>, [toprettystring(value)#116]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":240,"metricType":"sum"}]},"time":1759075844810,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":17,"accumUpdates":[[240,0]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":17,"time":1759075844812,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":16,"time":1759075844813,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":15,"time":1759075844813,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","name":null,"timestamp":"2025-09-28T16:10:44.454Z","batchId":0,"batchDuration":373,"durationMs":{"triggerExecution":373,"queryPlanning":18,"getBatch":3,"commitOffsets":14,"latestOffset":38,"addBatch":281,"walCommit":17},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":null,"endOffset":"{\"test-topic\":{\"0\":50}}","latestOffset":"{\"test-topic\":{\"0\":50}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":0,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:10:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:10:50.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:11:00.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:11:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:11:00.001Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":18,"rootExecutionId":18,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@774dfbfe\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@3dbbc5d9","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":245,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":248,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":252,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":242,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075880060,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":19,"rootExecutionId":19,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@54c54ee7\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2215a145","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":246,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":247,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":250,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":241,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075880060,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":21,"rootExecutionId":18,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@c6fa7eb\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@3dbbc5d9","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":245,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":248,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":252,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":242,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075880068,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":22,"rootExecutionId":19,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@676311d8\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2215a145","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":246,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":247,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":250,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":241,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075880069,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":20,"rootExecutionId":20,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@615556b4\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2014aada","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":244,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":249,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":251,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":243,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075880060,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":22,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":21,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":6,"Submission Time":1759075880078,"Stage Infos":[{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"40\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"DataSourceRDD","Scope":"{\"id\":\"45\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[6],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"22","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"19","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"40\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"DataSourceRDD","Scope":"{\"id\":\"45\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075880079,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"22","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"19","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":23,"rootExecutionId":20,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@7cbd17d1\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2014aada","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":244,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":249,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":251,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":243,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075880080,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"SparkListenerJobStart","Job ID":7,"Submission Time":1759075880088,"Stage Infos":[{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"39\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[23],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"46\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"DataSourceRDD","Scope":"{\"id\":\"46\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[7],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"21","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"18","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":23,"accumUpdates":[]}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"39\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[23],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"46\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"DataSourceRDD","Scope":"{\"id\":\"46\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075880091,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"21","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"18","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075880085,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerJobStart","Job ID":8,"Submission Time":1759075880101,"Stage Infos":[{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"47\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"DataSourceRDD","Scope":"{\"id\":\"50\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"50\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[8],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"23","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"20","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"47\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"DataSourceRDD","Scope":"{\"id\":\"50\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"50\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075880103,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"23","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"20","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075880100,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075880650,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075880100,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075880653,"Failed":false,"Killed":false,"Accumulables":[{"ID":242,"Name":"duration","Update":"520","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":245,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":288,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":289,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8359535,"Value":8359535,"Internal":true,"Count Failed Values":true},{"ID":290,"Name":"internal.metrics.executorRunTime","Update":523,"Value":523,"Internal":true,"Count Failed Values":true},{"ID":291,"Name":"internal.metrics.executorCpuTime","Update":20230287,"Value":20230287,"Internal":true,"Count Failed Values":true},{"ID":292,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":320,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":8359535,"Executor Run Time":523,"Executor CPU Time":20230287,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"39\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[23],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"46\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"DataSourceRDD","Scope":"{\"id\":\"46\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075880091,"Completion Time":1759075880654,"Accumulables":[{"ID":242,"Name":"duration","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":245,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":288,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":289,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8359535,"Internal":true,"Count Failed Values":true},{"ID":290,"Name":"internal.metrics.executorRunTime","Value":523,"Internal":true,"Count Failed Values":true},{"ID":291,"Name":"internal.metrics.executorCpuTime","Value":20230287,"Internal":true,"Count Failed Values":true},{"ID":292,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":320,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":7,"Completion Time":1759075880654,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075880085,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075880660,"Failed":false,"Killed":false,"Accumulables":[{"ID":241,"Name":"duration","Update":"541","Value":"541","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":246,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":253,"Name":"internal.metrics.executorDeserializeTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":254,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9557199,"Value":9557199,"Internal":true,"Count Failed Values":true},{"ID":255,"Name":"internal.metrics.executorRunTime","Update":543,"Value":543,"Internal":true,"Count Failed Values":true},{"ID":256,"Name":"internal.metrics.executorCpuTime","Update":36745374,"Value":36745374,"Internal":true,"Count Failed Values":true},{"ID":257,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":285,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":18,"Executor Deserialize CPU Time":9557199,"Executor Run Time":543,"Executor CPU Time":36745374,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"40\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"DataSourceRDD","Scope":"{\"id\":\"45\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075880079,"Completion Time":1759075880661,"Accumulables":[{"ID":241,"Name":"duration","Value":"541","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":246,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":253,"Name":"internal.metrics.executorDeserializeTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":254,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9557199,"Internal":true,"Count Failed Values":true},{"ID":255,"Name":"internal.metrics.executorRunTime","Value":543,"Internal":true,"Count Failed Values":true},{"ID":256,"Name":"internal.metrics.executorCpuTime","Value":36745374,"Internal":true,"Count Failed Values":true},{"ID":257,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":285,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":6,"Completion Time":1759075880662,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":24,"rootExecutionId":18,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#127]\nArguments: [toprettystring(value)#127]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#127]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":358,"metricType":"sum"}]},"time":1759075880674,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":25,"rootExecutionId":19,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#131]\nArguments: [toprettystring(value)#131]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#131]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":359,"metricType":"sum"}]},"time":1759075880679,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":24,"accumUpdates":[[358,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":24,"time":1759075880683,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":21,"time":1759075880684,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":18,"time":1759075880684,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":25,"accumUpdates":[[359,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":25,"time":1759075880689,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":22,"time":1759075880690,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":19,"time":1759075880690,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","name":null,"timestamp":"2025-09-28T16:11:20.000Z","batchId":3,"batchDuration":711,"durationMs":{"triggerExecution":711,"queryPlanning":9,"getBatch":0,"commitOffsets":26,"latestOffset":16,"addBatch":630,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":50}}","endOffset":"{\"test-topic\":{\"0\":60}}","latestOffset":"{\"test-topic\":{\"0\":60}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":14.064697609001406,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","name":null,"timestamp":"2025-09-28T16:11:20.000Z","batchId":1,"batchDuration":714,"durationMs":{"triggerExecution":714,"queryPlanning":8,"getBatch":0,"commitOffsets":23,"latestOffset":16,"addBatch":636,"walCommit":30},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":50}}","endOffset":"{\"test-topic\":{\"0\":60}}","latestOffset":"{\"test-topic\":{\"0\":60}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":14.005602240896359,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075880650,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075881219,"Failed":false,"Killed":false,"Accumulables":[{"ID":243,"Name":"duration","Update":"521","Value":"521","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":244,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":323,"Name":"internal.metrics.executorDeserializeTime","Update":36,"Value":36,"Internal":true,"Count Failed Values":true},{"ID":324,"Name":"internal.metrics.executorDeserializeCpuTime","Update":11872745,"Value":11872745,"Internal":true,"Count Failed Values":true},{"ID":325,"Name":"internal.metrics.executorRunTime","Update":523,"Value":523,"Internal":true,"Count Failed Values":true},{"ID":326,"Name":"internal.metrics.executorCpuTime","Update":20779143,"Value":20779143,"Internal":true,"Count Failed Values":true},{"ID":327,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":355,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":121740608,"JVMOffHeapMemory":84987096,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":75755,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":75755,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16798908,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":5,"MinorGCTime":44,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":44},"Task Metrics":{"Executor Deserialize Time":36,"Executor Deserialize CPU Time":11872745,"Executor Run Time":523,"Executor CPU Time":20779143,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"47\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"DataSourceRDD","Scope":"{\"id\":\"50\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"50\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075880103,"Completion Time":1759075881220,"Accumulables":[{"ID":243,"Name":"duration","Value":"521","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":244,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":323,"Name":"internal.metrics.executorDeserializeTime","Value":36,"Internal":true,"Count Failed Values":true},{"ID":324,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11872745,"Internal":true,"Count Failed Values":true},{"ID":325,"Name":"internal.metrics.executorRunTime","Value":523,"Internal":true,"Count Failed Values":true},{"ID":326,"Name":"internal.metrics.executorCpuTime","Value":20779143,"Internal":true,"Count Failed Values":true},{"ID":327,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":355,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":8,"Completion Time":1759075881220,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":26,"rootExecutionId":20,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#140]\nArguments: [toprettystring(value)#140]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#140]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":360,"metricType":"sum"}]},"time":1759075881233,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":26,"accumUpdates":[[360,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":26,"time":1759075881237,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":23,"time":1759075881237,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":20,"time":1759075881237,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","name":null,"timestamp":"2025-09-28T16:11:20.000Z","batchId":2,"batchDuration":1257,"durationMs":{"triggerExecution":1257,"queryPlanning":10,"getBatch":0,"commitOffsets":18,"latestOffset":12,"addBatch":1183,"walCommit":30},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":50}}","endOffset":"{\"test-topic\":{\"0\":60}}","latestOffset":"{\"test-topic\":{\"0\":60}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":7.9554494828957845,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","name":null,"timestamp":"2025-09-28T16:11:29.359Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":27,"rootExecutionId":27,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#152 as string) AS value#165]\nInput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#165]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@25fa2192\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@14fde34c","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#152 as string) AS value#165]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":362,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":363,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":364,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":361,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075889455,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":28,"rootExecutionId":27,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#152 as string) AS value#165]\nInput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#165]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@32878541\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@14fde34c","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#152 as string) AS value#165]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":362,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":363,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":364,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":361,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759075889464,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":28,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":9,"Submission Time":1759075889476,"Stage Infos":[{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":33,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"64\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[9],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"504a73a5-5cf2-452e-a554-7967662dd93c","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"28","sql.streaming.queryId":"e82bef1a-615f-4174-9543-8a5fe37ecb27","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"27","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":33,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"64\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075889477,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"504a73a5-5cf2-452e-a554-7967662dd93c","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"28","sql.streaming.queryId":"e82bef1a-615f-4174-9543-8a5fe37ecb27","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"27","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075889481,"Executor ID":"0","Host":"172.18.0.8","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759075889481,"Executor ID":"0","Host":"172.18.0.8","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759075889507,"Failed":false,"Killed":false,"Accumulables":[{"ID":365,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":366,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10648516,"Value":10648516,"Internal":true,"Count Failed Values":true},{"ID":367,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":368,"Name":"internal.metrics.executorCpuTime","Update":3089096,"Value":3089096,"Internal":true,"Count Failed Values":true},{"ID":369,"Name":"internal.metrics.resultSize","Update":1209,"Value":1209,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":10648516,"Executor Run Time":3,"Executor CPU Time":3089096,"Peak Execution Memory":0,"Result Size":1209,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":33,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"64\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759075889477,"Completion Time":1759075889508,"Accumulables":[{"ID":365,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":366,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10648516,"Internal":true,"Count Failed Values":true},{"ID":367,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":368,"Name":"internal.metrics.executorCpuTime","Value":3089096,"Internal":true,"Count Failed Values":true},{"ID":369,"Name":"internal.metrics.resultSize","Value":1209,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":9,"Completion Time":1759075889508,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":29,"rootExecutionId":27,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#172]\nArguments: <empty>, [toprettystring(value)#172]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan <empty>, [toprettystring(value)#172]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":400,"metricType":"sum"}]},"time":1759075889523,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":29,"accumUpdates":[[400,0]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":29,"time":1759075889528,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":28,"time":1759075889529,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":27,"time":1759075889529,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","name":null,"timestamp":"2025-09-28T16:11:29.360Z","batchId":0,"batchDuration":189,"durationMs":{"triggerExecution":189,"queryPlanning":15,"getBatch":2,"commitOffsets":20,"latestOffset":44,"addBatch":86,"walCommit":20},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":null,"endOffset":"{\"test-topic\":{\"0\":60}}","latestOffset":"{\"test-topic\":{\"0\":60}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":0,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:11:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:11:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:11:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:11:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:12:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:12:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:12:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:12:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:12:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:12:20.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:12:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:12:20.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:12:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:12:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:12:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:12:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:12:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:12:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:12:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:12:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:12:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:13:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:13:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:13:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:13:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:13:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:13:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:13:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:13:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:13:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:13:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:13:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:13:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:14:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:14:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:14:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:14:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:14:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:14:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:14:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:14:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:14:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:14:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:14:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:14:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:14:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:14:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:14:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:14:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:14:50.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:14:50.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:14:50.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:14:50.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","name":null,"timestamp":"2025-09-28T16:15:06.651Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":30,"rootExecutionId":30,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#184 as string) AS value#197]\nInput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#197]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@1065a7a0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@33bec81e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#184 as string) AS value#197]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":402,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":403,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":404,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":401,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076106790,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":31,"rootExecutionId":30,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#184 as string) AS value#197]\nInput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#197]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@1246af66\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@33bec81e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#184 as string) AS value#197]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":402,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":403,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":404,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":401,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076106795,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":31,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":10,"Submission Time":1759076106806,"Stage Infos":[{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":37,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"70\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[10],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"a63fb51b-85ed-4338-bce3-aed908edefc9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"31","sql.streaming.queryId":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"30","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":37,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"70\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076106807,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"a63fb51b-85ed-4338-bce3-aed908edefc9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"31","sql.streaming.queryId":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"30","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076106811,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076106811,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076106837,"Failed":false,"Killed":false,"Accumulables":[{"ID":405,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":406,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7374592,"Value":7374592,"Internal":true,"Count Failed Values":true},{"ID":408,"Name":"internal.metrics.executorCpuTime","Update":847709,"Value":847709,"Internal":true,"Count Failed Values":true},{"ID":409,"Name":"internal.metrics.resultSize","Update":1166,"Value":1166,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":7374592,"Executor Run Time":0,"Executor CPU Time":847709,"Peak Execution Memory":0,"Result Size":1166,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":37,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"70\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076106807,"Completion Time":1759076106838,"Accumulables":[{"ID":405,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":406,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7374592,"Internal":true,"Count Failed Values":true},{"ID":408,"Name":"internal.metrics.executorCpuTime","Value":847709,"Internal":true,"Count Failed Values":true},{"ID":409,"Name":"internal.metrics.resultSize","Value":1166,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":10,"Completion Time":1759076106839,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":32,"rootExecutionId":30,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#204]\nArguments: <empty>, [toprettystring(value)#204]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan <empty>, [toprettystring(value)#204]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":440,"metricType":"sum"}]},"time":1759076106858,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":32,"accumUpdates":[[440,0]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":32,"time":1759076106862,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":31,"time":1759076106862,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":30,"time":1759076106862,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","name":null,"timestamp":"2025-09-28T16:15:06.653Z","batchId":0,"batchDuration":229,"durationMs":{"triggerExecution":229,"queryPlanning":15,"getBatch":3,"commitOffsets":20,"latestOffset":81,"addBatch":77,"walCommit":33},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":null,"endOffset":"{\"test-topic\":{\"0\":60}}","latestOffset":"{\"test-topic\":{\"0\":60}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":0,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:15:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:15:10.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:15:10.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:15:10.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:15:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:15:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:15:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:15:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:15:20.000Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":33,"rootExecutionId":33,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4fdeb496\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@573baece","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":444,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":445,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":446,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":441,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130062,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":34,"rootExecutionId":34,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@46278348\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@6a7b7d02","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":447,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":449,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":450,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":443,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130063,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":35,"rootExecutionId":35,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#184 as string) AS value#197]\nInput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#197]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@793cc9e1\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@96d8c32","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#184 as string) AS value#197]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":448,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":451,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":452,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":442,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130063,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":36,"rootExecutionId":36,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@1ee6a94c\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@60d9dc8b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":454,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":455,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":456,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":453,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130065,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":39,"rootExecutionId":34,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@49d20457\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@6a7b7d02","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":447,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":449,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":450,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":443,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130070,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":37,"rootExecutionId":37,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#152 as string) AS value#165]\nInput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#165]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@64204a90\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4d862a93","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#152 as string) AS value#165]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":458,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":459,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":460,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":457,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130070,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":40,"rootExecutionId":35,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#184 as string) AS value#197]\nInput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#197]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@77ecacba\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@96d8c32","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#184 as string) AS value#197]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":448,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":451,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":452,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":442,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130072,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":38,"rootExecutionId":33,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5d013141\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@573baece","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":444,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":445,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":446,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":441,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130073,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":41,"rootExecutionId":36,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4bf8ea88\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@60d9dc8b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":454,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":455,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":456,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":453,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130076,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":39,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":40,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":38,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":42,"rootExecutionId":37,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#152 as string) AS value#165]\nInput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#165]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@22deb922\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4d862a93","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#152 as string) AS value#165]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":458,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":459,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":460,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":457,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076130079,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":41,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":11,"Submission Time":1759076130082,"Stage Infos":[{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"72\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"DataSourceRDD","Scope":"{\"id\":\"81\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"81\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[11],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"39","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"34","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"72\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"DataSourceRDD","Scope":"{\"id\":\"81\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"81\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130084,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"39","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"34","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":42,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":12,"Submission Time":1759076130090,"Stage Infos":[{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"75\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"DataSourceRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[12],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"a63fb51b-85ed-4338-bce3-aed908edefc9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"40","sql.streaming.queryId":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"35","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"75\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"DataSourceRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130091,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"a63fb51b-85ed-4338-bce3-aed908edefc9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"40","sql.streaming.queryId":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"35","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerJobStart","Job ID":13,"Submission Time":1759076130107,"Stage Infos":[{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"82\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"DataSourceRDD","Scope":"{\"id\":\"82\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[13],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"38","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"4","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 4","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"33","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"82\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"DataSourceRDD","Scope":"{\"id\":\"82\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130109,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"38","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"4","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 4","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"33","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerJobStart","Job ID":14,"Submission Time":1759076130117,"Stage Infos":[{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"84\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"DataSourceRDD","Scope":"{\"id\":\"87\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"87\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[14],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"41","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"36","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"84\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"DataSourceRDD","Scope":"{\"id\":\"87\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"87\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130118,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"41","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"36","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":11,"Stage Attempt ID":0,"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076130088,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerJobStart","Job ID":15,"Submission Time":1759076130135,"Stage Infos":[{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"88\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"91\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"DataSourceRDD","Scope":"{\"id\":\"91\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[15],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"504a73a5-5cf2-452e-a554-7967662dd93c","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"42","sql.streaming.queryId":"e82bef1a-615f-4174-9543-8a5fe37ecb27","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"37","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"88\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"91\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"DataSourceRDD","Scope":"{\"id\":\"91\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130141,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"504a73a5-5cf2-452e-a554-7967662dd93c","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"42","sql.streaming.queryId":"e82bef1a-615f-4174-9543-8a5fe37ecb27","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"37","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":12,"Stage Attempt ID":0,"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076130101,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":13,"Stage Attempt ID":0,"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076130676,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":11,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076130088,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076130677,"Failed":false,"Killed":false,"Accumulables":[{"ID":443,"Name":"duration","Update":"527","Value":"527","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":447,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":461,"Name":"internal.metrics.executorDeserializeTime","Update":46,"Value":46,"Internal":true,"Count Failed Values":true},{"ID":462,"Name":"internal.metrics.executorDeserializeCpuTime","Update":12075076,"Value":12075076,"Internal":true,"Count Failed Values":true},{"ID":463,"Name":"internal.metrics.executorRunTime","Update":533,"Value":533,"Internal":true,"Count Failed Values":true},{"ID":464,"Name":"internal.metrics.executorCpuTime","Update":24702771,"Value":24702771,"Internal":true,"Count Failed Values":true},{"ID":465,"Name":"internal.metrics.resultSize","Update":2544,"Value":2544,"Internal":true,"Count Failed Values":true},{"ID":466,"Name":"internal.metrics.jvmGCTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":493,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":68321792,"JVMOffHeapMemory":86330672,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":33645,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":33645,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16798984,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":6,"MinorGCTime":57,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":57},"Task Metrics":{"Executor Deserialize Time":46,"Executor Deserialize CPU Time":12075076,"Executor Run Time":533,"Executor CPU Time":24702771,"Peak Execution Memory":0,"Result Size":2544,"JVM GC Time":13,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"72\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"DataSourceRDD","Scope":"{\"id\":\"81\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"81\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130084,"Completion Time":1759076130679,"Accumulables":[{"ID":443,"Name":"duration","Value":"527","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":447,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":461,"Name":"internal.metrics.executorDeserializeTime","Value":46,"Internal":true,"Count Failed Values":true},{"ID":462,"Name":"internal.metrics.executorDeserializeCpuTime","Value":12075076,"Internal":true,"Count Failed Values":true},{"ID":463,"Name":"internal.metrics.executorRunTime","Value":533,"Internal":true,"Count Failed Values":true},{"ID":464,"Name":"internal.metrics.executorCpuTime","Value":24702771,"Internal":true,"Count Failed Values":true},{"ID":465,"Name":"internal.metrics.resultSize","Value":2544,"Internal":true,"Count Failed Values":true},{"ID":466,"Name":"internal.metrics.jvmGCTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":493,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":11,"Completion Time":1759076130679,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerTaskStart","Stage ID":14,"Stage Attempt ID":0,"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076130692,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":43,"rootExecutionId":34,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#216]\nArguments: [toprettystring(value)#216]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#216]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":636,"metricType":"sum"}]},"time":1759076130694,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"SparkListenerTaskEnd","Stage ID":12,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076130101,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076130693,"Failed":false,"Killed":false,"Accumulables":[{"ID":442,"Name":"duration","Update":"542","Value":"542","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":448,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":496,"Name":"internal.metrics.executorDeserializeTime","Update":31,"Value":31,"Internal":true,"Count Failed Values":true},{"ID":497,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10685729,"Value":10685729,"Internal":true,"Count Failed Values":true},{"ID":498,"Name":"internal.metrics.executorRunTime","Update":543,"Value":543,"Internal":true,"Count Failed Values":true},{"ID":499,"Name":"internal.metrics.executorCpuTime","Update":35229912,"Value":35229912,"Internal":true,"Count Failed Values":true},{"ID":500,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":528,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":68321792,"JVMOffHeapMemory":86330672,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":33645,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":33645,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16798984,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":6,"MinorGCTime":57,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":57},"Task Metrics":{"Executor Deserialize Time":31,"Executor Deserialize CPU Time":10685729,"Executor Run Time":543,"Executor CPU Time":35229912,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"75\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"DataSourceRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130091,"Completion Time":1759076130696,"Accumulables":[{"ID":442,"Name":"duration","Value":"542","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":448,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":496,"Name":"internal.metrics.executorDeserializeTime","Value":31,"Internal":true,"Count Failed Values":true},{"ID":497,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10685729,"Internal":true,"Count Failed Values":true},{"ID":498,"Name":"internal.metrics.executorRunTime","Value":543,"Internal":true,"Count Failed Values":true},{"ID":499,"Name":"internal.metrics.executorCpuTime","Value":35229912,"Internal":true,"Count Failed Values":true},{"ID":500,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":528,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":12,"Completion Time":1759076130697,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":43,"accumUpdates":[[636,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":43,"time":1759076130705,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":39,"time":1759076130708,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":34,"time":1759076130708,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":44,"rootExecutionId":35,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#223]\nArguments: [toprettystring(value)#223]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#223]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":637,"metricType":"sum"}]},"time":1759076130721,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":44,"accumUpdates":[[637,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":44,"time":1759076130728,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":40,"time":1759076130730,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":35,"time":1759076130730,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","name":null,"timestamp":"2025-09-28T16:15:30.001Z","batchId":2,"batchDuration":738,"durationMs":{"triggerExecution":738,"queryPlanning":9,"getBatch":0,"commitOffsets":29,"latestOffset":8,"addBatch":654,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":60}}","endOffset":"{\"test-topic\":{\"0\":70}}","latestOffset":"{\"test-topic\":{\"0\":70}}","numInputRows":10,"inputRowsPerSecond":0.9999000099990002,"processedRowsPerSecond":13.550135501355014,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","name":null,"timestamp":"2025-09-28T16:15:30.001Z","batchId":1,"batchDuration":748,"durationMs":{"triggerExecution":748,"queryPlanning":9,"getBatch":0,"commitOffsets":19,"latestOffset":8,"addBatch":676,"walCommit":36},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":60}}","endOffset":"{\"test-topic\":{\"0\":70}}","latestOffset":"{\"test-topic\":{\"0\":70}}","numInputRows":10,"inputRowsPerSecond":0.9999000099990002,"processedRowsPerSecond":13.368983957219251,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"SparkListenerTaskStart","Stage ID":15,"Stage Attempt ID":0,"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076131228,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":13,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076130676,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076131229,"Failed":false,"Killed":false,"Accumulables":[{"ID":441,"Name":"duration","Update":"529","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":444,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":531,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":532,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8904343,"Value":8904343,"Internal":true,"Count Failed Values":true},{"ID":533,"Name":"internal.metrics.executorRunTime","Update":531,"Value":531,"Internal":true,"Count Failed Values":true},{"ID":534,"Name":"internal.metrics.executorCpuTime","Update":24687609,"Value":24687609,"Internal":true,"Count Failed Values":true},{"ID":535,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":563,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":8904343,"Executor Run Time":531,"Executor CPU Time":24687609,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"82\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"DataSourceRDD","Scope":"{\"id\":\"82\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130109,"Completion Time":1759076131230,"Accumulables":[{"ID":441,"Name":"duration","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":444,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":531,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":532,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8904343,"Internal":true,"Count Failed Values":true},{"ID":533,"Name":"internal.metrics.executorRunTime","Value":531,"Internal":true,"Count Failed Values":true},{"ID":534,"Name":"internal.metrics.executorCpuTime","Value":24687609,"Internal":true,"Count Failed Values":true},{"ID":535,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":563,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":13,"Completion Time":1759076131230,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":45,"rootExecutionId":33,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#230]\nArguments: [toprettystring(value)#230]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#230]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":638,"metricType":"sum"}]},"time":1759076131244,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"SparkListenerTaskEnd","Stage ID":14,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076130692,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076131247,"Failed":false,"Killed":false,"Accumulables":[{"ID":453,"Name":"duration","Update":"522","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":454,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":566,"Name":"internal.metrics.executorDeserializeTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":567,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10196037,"Value":10196037,"Internal":true,"Count Failed Values":true},{"ID":568,"Name":"internal.metrics.executorRunTime","Update":523,"Value":523,"Internal":true,"Count Failed Values":true},{"ID":569,"Name":"internal.metrics.executorCpuTime","Update":20895284,"Value":20895284,"Internal":true,"Count Failed Values":true},{"ID":570,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":598,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":25,"Executor Deserialize CPU Time":10196037,"Executor Run Time":523,"Executor CPU Time":20895284,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"84\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"DataSourceRDD","Scope":"{\"id\":\"87\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"87\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130118,"Completion Time":1759076131248,"Accumulables":[{"ID":453,"Name":"duration","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":454,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":566,"Name":"internal.metrics.executorDeserializeTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":567,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10196037,"Internal":true,"Count Failed Values":true},{"ID":568,"Name":"internal.metrics.executorRunTime","Value":523,"Internal":true,"Count Failed Values":true},{"ID":569,"Name":"internal.metrics.executorCpuTime","Value":20895284,"Internal":true,"Count Failed Values":true},{"ID":570,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":598,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":14,"Completion Time":1759076131249,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":45,"accumUpdates":[[638,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":45,"time":1759076131252,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":38,"time":1759076131253,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":33,"time":1759076131253,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":46,"rootExecutionId":36,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#237]\nArguments: [toprettystring(value)#237]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#237]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":639,"metricType":"sum"}]},"time":1759076131269,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":46,"accumUpdates":[[639,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":46,"time":1759076131276,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":41,"time":1759076131277,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":36,"time":1759076131278,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","name":null,"timestamp":"2025-09-28T16:15:30.001Z","batchId":4,"batchDuration":1281,"durationMs":{"triggerExecution":1281,"queryPlanning":9,"getBatch":0,"commitOffsets":29,"latestOffset":8,"addBatch":1199,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":60}}","endOffset":"{\"test-topic\":{\"0\":70}}","latestOffset":"{\"test-topic\":{\"0\":70}}","numInputRows":10,"inputRowsPerSecond":0.9999000099990002,"processedRowsPerSecond":7.8064012490242005,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","name":null,"timestamp":"2025-09-28T16:15:30.001Z","batchId":3,"batchDuration":1292,"durationMs":{"triggerExecution":1292,"queryPlanning":9,"getBatch":0,"commitOffsets":15,"latestOffset":8,"addBatch":1223,"walCommit":36},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":60}}","endOffset":"{\"test-topic\":{\"0\":70}}","latestOffset":"{\"test-topic\":{\"0\":70}}","numInputRows":10,"inputRowsPerSecond":0.9999000099990002,"processedRowsPerSecond":7.739938080495356,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":15,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076131228,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076131791,"Failed":false,"Killed":false,"Accumulables":[{"ID":457,"Name":"duration","Update":"539","Value":"539","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":458,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":601,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":602,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7426038,"Value":7426038,"Internal":true,"Count Failed Values":true},{"ID":603,"Name":"internal.metrics.executorRunTime","Update":541,"Value":541,"Internal":true,"Count Failed Values":true},{"ID":604,"Name":"internal.metrics.executorCpuTime","Update":32452347,"Value":32452347,"Internal":true,"Count Failed Values":true},{"ID":605,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":633,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":7426038,"Executor Run Time":541,"Executor CPU Time":32452347,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"88\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"91\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"DataSourceRDD","Scope":"{\"id\":\"91\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076130141,"Completion Time":1759076131792,"Accumulables":[{"ID":457,"Name":"duration","Value":"539","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":458,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":601,"Name":"internal.metrics.executorDeserializeTime","Value":12,"Internal":true,"Count Failed Values":true},{"ID":602,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7426038,"Internal":true,"Count Failed Values":true},{"ID":603,"Name":"internal.metrics.executorRunTime","Value":541,"Internal":true,"Count Failed Values":true},{"ID":604,"Name":"internal.metrics.executorCpuTime","Value":32452347,"Internal":true,"Count Failed Values":true},{"ID":605,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":633,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":15,"Completion Time":1759076131793,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":47,"rootExecutionId":37,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#244]\nArguments: [toprettystring(value)#244]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#244]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":640,"metricType":"sum"}]},"time":1759076131806,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":47,"accumUpdates":[[640,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":47,"time":1759076131811,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":42,"time":1759076131812,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":37,"time":1759076131812,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","name":null,"timestamp":"2025-09-28T16:15:30.001Z","batchId":1,"batchDuration":1828,"durationMs":{"triggerExecution":1828,"queryPlanning":12,"getBatch":0,"commitOffsets":17,"latestOffset":8,"addBatch":1750,"walCommit":40},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":60}}","endOffset":"{\"test-topic\":{\"0\":70}}","latestOffset":"{\"test-topic\":{\"0\":70}}","numInputRows":10,"inputRowsPerSecond":0.9999000099990002,"processedRowsPerSecond":5.470459518599562,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","name":null,"timestamp":"2025-09-28T16:15:40.421Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":48,"rootExecutionId":48,"description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#256 as string) AS value#269]\nInput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#269]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@50682374\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@1c6ef7f5","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#256 as string) AS value#269]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":642,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":643,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":644,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":641,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076140490,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":49,"rootExecutionId":48,"description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#256 as string) AS value#269]\nInput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#269]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@15ba63f7\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@1c6ef7f5","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#256 as string) AS value#269]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":642,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":643,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":644,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":641,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076140497,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":49,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":16,"Submission Time":1759076140511,"Stage Infos":[{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":56,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"111\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[16],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"021060e4-10f0-4893-98aa-7839134220e6","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"49","sql.streaming.queryId":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"48","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":56,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"111\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076140512,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"021060e4-10f0-4893-98aa-7839134220e6","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"49","sql.streaming.queryId":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"48","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":16,"Stage Attempt ID":0,"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076140516,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":16,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076140516,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076140542,"Failed":false,"Killed":false,"Accumulables":[{"ID":645,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":646,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8979815,"Value":8979815,"Internal":true,"Count Failed Values":true},{"ID":647,"Name":"internal.metrics.executorRunTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":648,"Name":"internal.metrics.executorCpuTime","Update":1571016,"Value":1571016,"Internal":true,"Count Failed Values":true},{"ID":649,"Name":"internal.metrics.resultSize","Update":1252,"Value":1252,"Internal":true,"Count Failed Values":true},{"ID":651,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":8979815,"Executor Run Time":1,"Executor CPU Time":1571016,"Peak Execution Memory":0,"Result Size":1252,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":56,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"111\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076140512,"Completion Time":1759076140543,"Accumulables":[{"ID":645,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":646,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8979815,"Internal":true,"Count Failed Values":true},{"ID":647,"Name":"internal.metrics.executorRunTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":648,"Name":"internal.metrics.executorCpuTime","Value":1571016,"Internal":true,"Count Failed Values":true},{"ID":649,"Name":"internal.metrics.resultSize","Value":1252,"Internal":true,"Count Failed Values":true},{"ID":651,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":16,"Completion Time":1759076140543,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":50,"rootExecutionId":48,"description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#276]\nArguments: <empty>, [toprettystring(value)#276]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan <empty>, [toprettystring(value)#276]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":680,"metricType":"sum"}]},"time":1759076140553,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":50,"accumUpdates":[[680,0]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":50,"time":1759076140556,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":49,"time":1759076140556,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":48,"time":1759076140556,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","name":null,"timestamp":"2025-09-28T16:15:40.424Z","batchId":0,"batchDuration":148,"durationMs":{"triggerExecution":148,"queryPlanning":8,"getBatch":1,"commitOffsets":16,"latestOffset":34,"addBatch":73,"walCommit":14},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":null,"endOffset":"{\"test-topic\":{\"0\":70}}","latestOffset":"{\"test-topic\":{\"0\":70}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":0,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:15:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:15:50.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:15:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:15:50.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:15:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","name":null,"timestamp":"2025-09-28T16:15:59.012Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":51,"rootExecutionId":51,"description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#288 as string) AS value#301]\nInput [7]: [key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#301]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4e8d9870\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@ee778b6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#288 as string) AS value#301]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":682,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":683,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":684,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":681,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076159098,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":52,"rootExecutionId":51,"description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#288 as string) AS value#301]\nInput [7]: [key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#301]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@26ef2bfa\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@ee778b6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#288 as string) AS value#301]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":682,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":683,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":684,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":681,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076159107,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":52,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":17,"Submission Time":1759076159116,"Stage Infos":[{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":60,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"117\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[17],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"52","sql.streaming.queryId":"faf9fcb3-f05f-405c-b2f3-266f89c764de","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"51","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":60,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"117\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076159121,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"52","sql.streaming.queryId":"faf9fcb3-f05f-405c-b2f3-266f89c764de","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"51","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":17,"Stage Attempt ID":0,"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076159125,"Executor ID":"0","Host":"172.18.0.8","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":17,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076159125,"Executor ID":"0","Host":"172.18.0.8","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076159151,"Failed":false,"Killed":false,"Accumulables":[{"ID":685,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":686,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10147184,"Value":10147184,"Internal":true,"Count Failed Values":true},{"ID":687,"Name":"internal.metrics.executorRunTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":688,"Name":"internal.metrics.executorCpuTime","Update":1397623,"Value":1397623,"Internal":true,"Count Failed Values":true},{"ID":689,"Name":"internal.metrics.resultSize","Update":1209,"Value":1209,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":10147184,"Executor Run Time":1,"Executor CPU Time":1397623,"Peak Execution Memory":0,"Result Size":1209,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":60,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"117\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076159121,"Completion Time":1759076159152,"Accumulables":[{"ID":685,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":686,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10147184,"Internal":true,"Count Failed Values":true},{"ID":687,"Name":"internal.metrics.executorRunTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":688,"Name":"internal.metrics.executorCpuTime","Value":1397623,"Internal":true,"Count Failed Values":true},{"ID":689,"Name":"internal.metrics.resultSize","Value":1209,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":17,"Completion Time":1759076159153,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":53,"rootExecutionId":51,"description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#308]\nArguments: <empty>, [toprettystring(value)#308]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan <empty>, [toprettystring(value)#308]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":720,"metricType":"sum"}]},"time":1759076159162,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":53,"accumUpdates":[[720,0]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":53,"time":1759076159165,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":52,"time":1759076159166,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":51,"time":1759076159166,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","name":null,"timestamp":"2025-09-28T16:15:59.015Z","batchId":0,"batchDuration":170,"durationMs":{"triggerExecution":170,"queryPlanning":12,"getBatch":1,"commitOffsets":19,"latestOffset":36,"addBatch":77,"walCommit":24},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":null,"endOffset":"{\"test-topic\":{\"0\":80}}","latestOffset":"{\"test-topic\":{\"0\":80}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":0,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":54,"rootExecutionId":54,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#184 as string) AS value#197]\nInput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#197]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@724fda1\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@61ecae6e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#184 as string) AS value#197]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":722,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":723,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":724,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":721,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160056,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":56,"rootExecutionId":56,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@27d197ef\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5f804350","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":726,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":727,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":728,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":725,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160063,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":55,"rootExecutionId":55,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5ab0e9fa\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@6c4ec94f","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":730,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":731,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":732,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":729,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160065,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":57,"rootExecutionId":54,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#184 as string) AS value#197]\nInput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#197]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@c4c4976\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@61ecae6e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#184 as string) AS value#197]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":722,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":723,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":724,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":721,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160070,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":59,"rootExecutionId":56,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@746e7e65\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5f804350","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":726,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":727,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":728,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":725,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160075,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":57,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":61,"rootExecutionId":55,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@13ecbb6f\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@6c4ec94f","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":730,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":731,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":732,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":729,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160077,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":58,"rootExecutionId":58,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#152 as string) AS value#165]\nInput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#165]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@51391a4c\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2f93a57","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#152 as string) AS value#165]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":734,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":735,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":736,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":733,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160077,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"SparkListenerJobStart","Job ID":18,"Submission Time":1759076160082,"Stage Infos":[{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"119\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"DataSourceRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[18],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"a63fb51b-85ed-4338-bce3-aed908edefc9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"57","sql.streaming.queryId":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"54","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":59,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":60,"rootExecutionId":60,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 5, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@a22ba9a\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 5, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@57177f8e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":739,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":740,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":741,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":738,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160083,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"119\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"DataSourceRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160084,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"a63fb51b-85ed-4338-bce3-aed908edefc9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"57","sql.streaming.queryId":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"54","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":62,"rootExecutionId":62,"description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#256 as string) AS value#269]\nInput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#269]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5acd2b26\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@3f25b024","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#256 as string) AS value#269]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":777,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":778,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":779,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":737,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160084,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":61,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":63,"rootExecutionId":58,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#152 as string) AS value#165]\nInput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#165]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@7534695d\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2f93a57","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#152 as string) AS value#165]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":734,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":735,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":736,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":733,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160089,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":64,"rootExecutionId":60,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 5, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@6a02458a\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 5, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@57177f8e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":739,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":740,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":741,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":738,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160090,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":63,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":19,"Submission Time":1759076160096,"Stage Infos":[{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"123\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"127\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"DataSourceRDD","Scope":"{\"id\":\"127\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[19],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"59","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"4","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 4","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"56","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":64,"accumUpdates":[]}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"123\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"127\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"DataSourceRDD","Scope":"{\"id\":\"127\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160103,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"59","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"4","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 4","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"56","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":65,"rootExecutionId":62,"description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#256 as string) AS value#269]\nInput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#269]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@3d8e6332\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@3f25b024","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#256 as string) AS value#269]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":777,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":778,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":779,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":737,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076160105,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"SparkListenerTaskStart","Stage ID":18,"Stage Attempt ID":0,"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076160091,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerJobStart","Job ID":20,"Submission Time":1759076160113,"Stage Infos":[{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"126\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"DataSourceRDD","Scope":"{\"id\":\"130\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"130\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[20],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"61","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"55","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":65,"accumUpdates":[]}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"126\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"DataSourceRDD","Scope":"{\"id\":\"130\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"130\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160114,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"61","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"55","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerJobStart","Job ID":21,"Submission Time":1759076160121,"Stage Infos":[{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":74,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"131\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"DataSourceRDD","Scope":"{\"id\":\"137\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"137\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[21],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"504a73a5-5cf2-452e-a554-7967662dd93c","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"63","sql.streaming.queryId":"e82bef1a-615f-4174-9543-8a5fe37ecb27","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"58","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":74,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"131\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"DataSourceRDD","Scope":"{\"id\":\"137\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"137\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160123,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"504a73a5-5cf2-452e-a554-7967662dd93c","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"63","sql.streaming.queryId":"e82bef1a-615f-4174-9543-8a5fe37ecb27","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"58","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerJobStart","Job ID":22,"Submission Time":1759076160129,"Stage Infos":[{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[73],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"138\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[71],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":71,"Name":"DataSourceRDD","Scope":"{\"id\":\"138\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[22],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"64","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"5","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 5","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"60","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[73],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"138\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[71],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":71,"Name":"DataSourceRDD","Scope":"{\"id\":\"138\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160131,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"64","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"5","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 5","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"60","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":19,"Stage Attempt ID":0,"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076160111,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerJobStart","Job ID":23,"Submission Time":1759076160141,"Stage Infos":[{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"139\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"DataSourceRDD","Scope":"{\"id\":\"142\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"142\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[23],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"021060e4-10f0-4893-98aa-7839134220e6","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"65","sql.streaming.queryId":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"62","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"139\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"DataSourceRDD","Scope":"{\"id\":\"142\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"142\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160143,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"021060e4-10f0-4893-98aa-7839134220e6","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"65","sql.streaming.queryId":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"62","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":20,"Stage Attempt ID":0,"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076160646,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":18,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076160091,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076160647,"Failed":false,"Killed":false,"Accumulables":[{"ID":721,"Name":"duration","Update":"520","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":722,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":742,"Name":"internal.metrics.executorDeserializeTime","Update":24,"Value":24,"Internal":true,"Count Failed Values":true},{"ID":743,"Name":"internal.metrics.executorDeserializeCpuTime","Update":11433904,"Value":11433904,"Internal":true,"Count Failed Values":true},{"ID":744,"Name":"internal.metrics.executorRunTime","Update":522,"Value":522,"Internal":true,"Count Failed Values":true},{"ID":745,"Name":"internal.metrics.executorCpuTime","Update":18332140,"Value":18332140,"Internal":true,"Count Failed Values":true},{"ID":746,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":774,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":24,"Executor Deserialize CPU Time":11433904,"Executor Run Time":522,"Executor CPU Time":18332140,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"119\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"DataSourceRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160084,"Completion Time":1759076160647,"Accumulables":[{"ID":721,"Name":"duration","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":722,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":742,"Name":"internal.metrics.executorDeserializeTime","Value":24,"Internal":true,"Count Failed Values":true},{"ID":743,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11433904,"Internal":true,"Count Failed Values":true},{"ID":744,"Name":"internal.metrics.executorRunTime","Value":522,"Internal":true,"Count Failed Values":true},{"ID":745,"Name":"internal.metrics.executorCpuTime","Value":18332140,"Internal":true,"Count Failed Values":true},{"ID":746,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":774,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":18,"Completion Time":1759076160648,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerTaskStart","Stage ID":21,"Stage Attempt ID":0,"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076160656,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":19,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076160111,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076160657,"Failed":false,"Killed":false,"Accumulables":[{"ID":725,"Name":"duration","Update":"519","Value":"519","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":726,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":780,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":781,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8650233,"Value":8650233,"Internal":true,"Count Failed Values":true},{"ID":782,"Name":"internal.metrics.executorRunTime","Update":520,"Value":520,"Internal":true,"Count Failed Values":true},{"ID":783,"Name":"internal.metrics.executorCpuTime","Update":17806548,"Value":17806548,"Internal":true,"Count Failed Values":true},{"ID":784,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":812,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":8650233,"Executor Run Time":520,"Executor CPU Time":17806548,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"123\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"127\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"DataSourceRDD","Scope":"{\"id\":\"127\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160103,"Completion Time":1759076160660,"Accumulables":[{"ID":725,"Name":"duration","Value":"519","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":726,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":780,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":781,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8650233,"Internal":true,"Count Failed Values":true},{"ID":782,"Name":"internal.metrics.executorRunTime","Value":520,"Internal":true,"Count Failed Values":true},{"ID":783,"Name":"internal.metrics.executorCpuTime","Value":17806548,"Internal":true,"Count Failed Values":true},{"ID":784,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":812,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":19,"Completion Time":1759076160660,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":66,"rootExecutionId":54,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#321]\nArguments: [toprettystring(value)#321]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#321]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":955,"metricType":"sum"}]},"time":1759076160667,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":66,"accumUpdates":[[955,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":66,"time":1759076160677,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":67,"rootExecutionId":56,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#326]\nArguments: [toprettystring(value)#326]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#326]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":956,"metricType":"sum"}]},"time":1759076160682,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":57,"time":1759076160682,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":54,"time":1759076160682,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":67,"accumUpdates":[[956,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":67,"time":1759076160689,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":59,"time":1759076160690,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":56,"time":1759076160690,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","name":null,"timestamp":"2025-09-28T16:16:00.001Z","batchId":2,"batchDuration":706,"durationMs":{"triggerExecution":706,"queryPlanning":8,"getBatch":0,"commitOffsets":25,"latestOffset":5,"addBatch":632,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":70}}","endOffset":"{\"test-topic\":{\"0\":80}}","latestOffset":"{\"test-topic\":{\"0\":80}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":14.164305949008499,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","name":null,"timestamp":"2025-09-28T16:16:00.000Z","batchId":4,"batchDuration":711,"durationMs":{"triggerExecution":711,"queryPlanning":10,"getBatch":0,"commitOffsets":20,"latestOffset":7,"addBatch":641,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":70}}","endOffset":"{\"test-topic\":{\"0\":80}}","latestOffset":"{\"test-topic\":{\"0\":80}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":14.064697609001406,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"SparkListenerTaskStart","Stage ID":22,"Stage Attempt ID":0,"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076161196,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":20,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076160646,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076161198,"Failed":false,"Killed":false,"Accumulables":[{"ID":729,"Name":"duration","Update":"520","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":730,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":815,"Name":"internal.metrics.executorDeserializeTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":816,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8314466,"Value":8314466,"Internal":true,"Count Failed Values":true},{"ID":817,"Name":"internal.metrics.executorRunTime","Update":521,"Value":521,"Internal":true,"Count Failed Values":true},{"ID":818,"Name":"internal.metrics.executorCpuTime","Update":17285537,"Value":17285537,"Internal":true,"Count Failed Values":true},{"ID":819,"Name":"internal.metrics.resultSize","Update":2544,"Value":2544,"Internal":true,"Count Failed Values":true},{"ID":821,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":847,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":93487616,"JVMOffHeapMemory":84429416,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":113997,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":113997,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16798984,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":6,"MinorGCTime":57,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":57},"Task Metrics":{"Executor Deserialize Time":20,"Executor Deserialize CPU Time":8314466,"Executor Run Time":521,"Executor CPU Time":17285537,"Peak Execution Memory":0,"Result Size":2544,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"126\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"DataSourceRDD","Scope":"{\"id\":\"130\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"130\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160114,"Completion Time":1759076161199,"Accumulables":[{"ID":729,"Name":"duration","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":730,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":815,"Name":"internal.metrics.executorDeserializeTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":816,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8314466,"Internal":true,"Count Failed Values":true},{"ID":817,"Name":"internal.metrics.executorRunTime","Value":521,"Internal":true,"Count Failed Values":true},{"ID":818,"Name":"internal.metrics.executorCpuTime","Value":17285537,"Internal":true,"Count Failed Values":true},{"ID":819,"Name":"internal.metrics.resultSize","Value":2544,"Internal":true,"Count Failed Values":true},{"ID":821,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":847,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":20,"Completion Time":1759076161199,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":68,"rootExecutionId":55,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#335]\nArguments: [toprettystring(value)#335]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#335]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":957,"metricType":"sum"}]},"time":1759076161214,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":68,"accumUpdates":[[957,10]]}
{"Event":"SparkListenerTaskStart","Stage ID":23,"Stage Attempt ID":0,"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076161220,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":21,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076160656,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076161221,"Failed":false,"Killed":false,"Accumulables":[{"ID":733,"Name":"duration","Update":"526","Value":"526","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":734,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":850,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":851,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7606234,"Value":7606234,"Internal":true,"Count Failed Values":true},{"ID":852,"Name":"internal.metrics.executorRunTime","Update":527,"Value":527,"Internal":true,"Count Failed Values":true},{"ID":853,"Name":"internal.metrics.executorCpuTime","Update":19140459,"Value":19140459,"Internal":true,"Count Failed Values":true},{"ID":854,"Name":"internal.metrics.resultSize","Update":2587,"Value":2587,"Internal":true,"Count Failed Values":true},{"ID":855,"Name":"internal.metrics.jvmGCTime","Update":8,"Value":8,"Internal":true,"Count Failed Values":true},{"ID":856,"Name":"internal.metrics.resultSerializationTime","Update":8,"Value":8,"Internal":true,"Count Failed Values":true},{"ID":882,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":93487616,"JVMOffHeapMemory":84429416,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":113997,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":113997,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16798984,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":6,"MinorGCTime":57,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":57},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":7606234,"Executor Run Time":527,"Executor CPU Time":19140459,"Peak Execution Memory":0,"Result Size":2587,"JVM GC Time":8,"Result Serialization Time":8,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":68,"time":1759076161222,"errorMessage":""}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":74,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"131\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"DataSourceRDD","Scope":"{\"id\":\"137\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"137\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160123,"Completion Time":1759076161222,"Accumulables":[{"ID":733,"Name":"duration","Value":"526","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":734,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":850,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":851,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7606234,"Internal":true,"Count Failed Values":true},{"ID":852,"Name":"internal.metrics.executorRunTime","Value":527,"Internal":true,"Count Failed Values":true},{"ID":853,"Name":"internal.metrics.executorCpuTime","Value":19140459,"Internal":true,"Count Failed Values":true},{"ID":854,"Name":"internal.metrics.resultSize","Value":2587,"Internal":true,"Count Failed Values":true},{"ID":855,"Name":"internal.metrics.jvmGCTime","Value":8,"Internal":true,"Count Failed Values":true},{"ID":856,"Name":"internal.metrics.resultSerializationTime","Value":8,"Internal":true,"Count Failed Values":true},{"ID":882,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":21,"Completion Time":1759076161222,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":61,"time":1759076161223,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":55,"time":1759076161223,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":69,"rootExecutionId":58,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#342]\nArguments: [toprettystring(value)#342]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#342]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":958,"metricType":"sum"}]},"time":1759076161239,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":69,"accumUpdates":[[958,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":69,"time":1759076161245,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":63,"time":1759076161246,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":58,"time":1759076161246,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","name":null,"timestamp":"2025-09-28T16:16:00.000Z","batchId":3,"batchDuration":1253,"durationMs":{"triggerExecution":1253,"queryPlanning":9,"getBatch":0,"commitOffsets":30,"latestOffset":6,"addBatch":1173,"walCommit":34},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":70}}","endOffset":"{\"test-topic\":{\"0\":80}}","latestOffset":"{\"test-topic\":{\"0\":80}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":7.980845969672786,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","name":null,"timestamp":"2025-09-28T16:16:00.000Z","batchId":2,"batchDuration":1275,"durationMs":{"triggerExecution":1275,"queryPlanning":7,"getBatch":1,"commitOffsets":29,"latestOffset":7,"addBatch":1190,"walCommit":40},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":70}}","endOffset":"{\"test-topic\":{\"0\":80}}","latestOffset":"{\"test-topic\":{\"0\":80}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":7.843137254901961,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":22,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076161196,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076161753,"Failed":false,"Killed":false,"Accumulables":[{"ID":738,"Name":"duration","Update":"520","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":739,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":885,"Name":"internal.metrics.executorDeserializeTime","Update":24,"Value":24,"Internal":true,"Count Failed Values":true},{"ID":886,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10443391,"Value":10443391,"Internal":true,"Count Failed Values":true},{"ID":887,"Name":"internal.metrics.executorRunTime","Update":522,"Value":522,"Internal":true,"Count Failed Values":true},{"ID":888,"Name":"internal.metrics.executorCpuTime","Update":17914757,"Value":17914757,"Internal":true,"Count Failed Values":true},{"ID":889,"Name":"internal.metrics.resultSize","Update":2544,"Value":2544,"Internal":true,"Count Failed Values":true},{"ID":890,"Name":"internal.metrics.jvmGCTime","Update":8,"Value":8,"Internal":true,"Count Failed Values":true},{"ID":917,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":24,"Executor Deserialize CPU Time":10443391,"Executor Run Time":522,"Executor CPU Time":17914757,"Peak Execution Memory":0,"Result Size":2544,"JVM GC Time":8,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[73],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"138\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[71],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":71,"Name":"DataSourceRDD","Scope":"{\"id\":\"138\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160131,"Completion Time":1759076161755,"Accumulables":[{"ID":738,"Name":"duration","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":739,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":885,"Name":"internal.metrics.executorDeserializeTime","Value":24,"Internal":true,"Count Failed Values":true},{"ID":886,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10443391,"Internal":true,"Count Failed Values":true},{"ID":887,"Name":"internal.metrics.executorRunTime","Value":522,"Internal":true,"Count Failed Values":true},{"ID":888,"Name":"internal.metrics.executorCpuTime","Value":17914757,"Internal":true,"Count Failed Values":true},{"ID":889,"Name":"internal.metrics.resultSize","Value":2544,"Internal":true,"Count Failed Values":true},{"ID":890,"Name":"internal.metrics.jvmGCTime","Value":8,"Internal":true,"Count Failed Values":true},{"ID":917,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":22,"Completion Time":1759076161755,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":70,"rootExecutionId":60,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#349]\nArguments: [toprettystring(value)#349]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#349]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":959,"metricType":"sum"}]},"time":1759076161774,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"SparkListenerTaskEnd","Stage ID":23,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076161220,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076161777,"Failed":false,"Killed":false,"Accumulables":[{"ID":737,"Name":"duration","Update":"533","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":777,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":920,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":921,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6880820,"Value":6880820,"Internal":true,"Count Failed Values":true},{"ID":922,"Name":"internal.metrics.executorRunTime","Update":534,"Value":534,"Internal":true,"Count Failed Values":true},{"ID":923,"Name":"internal.metrics.executorCpuTime","Update":26516955,"Value":26516955,"Internal":true,"Count Failed Values":true},{"ID":924,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":952,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":6880820,"Executor Run Time":534,"Executor CPU Time":26516955,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"139\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"DataSourceRDD","Scope":"{\"id\":\"142\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"142\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076160143,"Completion Time":1759076161778,"Accumulables":[{"ID":737,"Name":"duration","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":777,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":920,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":921,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6880820,"Internal":true,"Count Failed Values":true},{"ID":922,"Name":"internal.metrics.executorRunTime","Value":534,"Internal":true,"Count Failed Values":true},{"ID":923,"Name":"internal.metrics.executorCpuTime","Value":26516955,"Internal":true,"Count Failed Values":true},{"ID":924,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":952,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":23,"Completion Time":1759076161778,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":70,"accumUpdates":[[959,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":70,"time":1759076161781,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":64,"time":1759076161781,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":60,"time":1759076161781,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":71,"rootExecutionId":62,"description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#356]\nArguments: [toprettystring(value)#356]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#356]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":960,"metricType":"sum"}]},"time":1759076161790,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":71,"accumUpdates":[[960,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":71,"time":1759076161794,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":65,"time":1759076161794,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":62,"time":1759076161795,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","name":null,"timestamp":"2025-09-28T16:16:00.000Z","batchId":5,"batchDuration":1801,"durationMs":{"triggerExecution":1801,"queryPlanning":17,"getBatch":1,"commitOffsets":20,"latestOffset":11,"addBatch":1716,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":70}}","endOffset":"{\"test-topic\":{\"0\":80}}","latestOffset":"{\"test-topic\":{\"0\":80}}","numInputRows":10,"inputRowsPerSecond":1.000100010001,"processedRowsPerSecond":5.55247084952804,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","name":null,"timestamp":"2025-09-28T16:16:00.001Z","batchId":1,"batchDuration":1808,"durationMs":{"triggerExecution":1808,"queryPlanning":27,"getBatch":1,"commitOffsets":14,"latestOffset":6,"addBatch":1722,"walCommit":36},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":70}}","endOffset":"{\"test-topic\":{\"0\":80}}","latestOffset":"{\"test-topic\":{\"0\":80}}","numInputRows":10,"inputRowsPerSecond":0.9999000099990002,"processedRowsPerSecond":5.530973451327434,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:16:10.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:16:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:16:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:16:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:16:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:16:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:16:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:16:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:16:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:16:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:16:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:16:30.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:16:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:16:30.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:16:30.001Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":76,"rootExecutionId":76,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#184 as string) AS value#197]\nInput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#197]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@796db022\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@12fbd961","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#184 as string) AS value#197]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":971,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":972,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":973,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":963,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200057,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":73,"rootExecutionId":73,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 6, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4e835fee\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 6, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@1a6edab","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":966,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":967,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":969,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":962,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200057,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":72,"rootExecutionId":72,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 5, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@2e1a7726\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 5, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@65d32196","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":965,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":968,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":970,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":961,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200057,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":74,"rootExecutionId":74,"description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#288 as string) AS value#301]\nInput [7]: [key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#301]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@7d1554c0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@437656da","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#288 as string) AS value#301]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":974,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":975,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":976,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":964,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200057,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":75,"rootExecutionId":75,"description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#256 as string) AS value#269]\nInput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#269]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@16290e8\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@47935902","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#256 as string) AS value#269]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":979,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":981,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":983,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":977,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200059,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":77,"rootExecutionId":77,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#152 as string) AS value#165]\nInput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#165]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@46e24e56\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@534b12a0","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#152 as string) AS value#165]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":980,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":982,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":984,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":978,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200059,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":80,"rootExecutionId":73,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#8 as string) AS value#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#21]\nArguments: MicroBatchWrite[epoch: 6, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@390f3027\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 6, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@1a6edab","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#8 as string) AS value#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":966,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":967,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":969,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":962,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200068,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":78,"rootExecutionId":72,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#40 as string) AS value#53]\nInput [7]: [key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#53]\nArguments: MicroBatchWrite[epoch: 5, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@931d683\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 5, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@65d32196","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#40 as string) AS value#53]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#39, value#40, topic#41, partition#42, offset#43L, timestamp#44, timestampType#45] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":965,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":968,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":970,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":961,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200068,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":81,"rootExecutionId":74,"description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#288 as string) AS value#301]\nInput [7]: [key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#301]\nArguments: MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@6325b34b\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 1, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@437656da","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#288 as string) AS value#301]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#287, value#288, topic#289, partition#290, offset#291L, timestamp#292, timestampType#293] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":974,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":975,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":976,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":964,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200070,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":83,"rootExecutionId":77,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#152 as string) AS value#165]\nInput [7]: [key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#165]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@36b9f1a2\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@534b12a0","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#152 as string) AS value#165]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#151, value#152, topic#153, partition#154, offset#155L, timestamp#156, timestampType#157] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":980,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":982,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":984,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":978,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200070,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":79,"rootExecutionId":76,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#184 as string) AS value#197]\nInput [7]: [key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#197]\nArguments: MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@19496f\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 3, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@12fbd961","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#184 as string) AS value#197]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#183, value#184, topic#185, partition#186, offset#187L, timestamp#188, timestampType#189] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":971,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":972,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":973,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":963,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200070,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":83,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":81,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":78,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":82,"rootExecutionId":75,"description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#256 as string) AS value#269]\nInput [7]: [key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#269]\nArguments: MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@383fa86d\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 2, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@47935902","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#256 as string) AS value#269]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#255, value#256, topic#257, partition#258, offset#259L, timestamp#260, timestampType#261] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":979,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":981,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":983,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":977,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200073,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":79,"accumUpdates":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":80,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":24,"Submission Time":1759076200077,"Stage Infos":[{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"161\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[82],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"176\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"DataSourceRDD","Scope":"{\"id\":\"176\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[24],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"78","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"5","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 5","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"72","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":82,"accumUpdates":[]}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"161\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[82],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"176\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"DataSourceRDD","Scope":"{\"id\":\"176\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200080,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"4ec26920-25c9-4399-ab3a-36c141854e69","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"78","sql.streaming.queryId":"6566bf38-9f27-45c9-8891-497274cea14c","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"5","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 5","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"72","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerJobStart","Job ID":25,"Submission Time":1759076200084,"Stage Infos":[{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"167\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[86],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":86,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"177\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[79],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":79,"Name":"DataSourceRDD","Scope":"{\"id\":\"177\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[25],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"504a73a5-5cf2-452e-a554-7967662dd93c","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"83","sql.streaming.queryId":"e82bef1a-615f-4174-9543-8a5fe37ecb27","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"77","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"167\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[86],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":86,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"177\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[79],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":79,"Name":"DataSourceRDD","Scope":"{\"id\":\"177\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200085,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"504a73a5-5cf2-452e-a554-7967662dd93c","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"83","sql.streaming.queryId":"e82bef1a-615f-4174-9543-8a5fe37ecb27","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"77","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerJobStart","Job ID":26,"Submission Time":1759076200091,"Stage Infos":[{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"168\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"DataSourceRDD","Scope":"{\"id\":\"178\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"178\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[26],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"81","sql.streaming.queryId":"faf9fcb3-f05f-405c-b2f3-266f89c764de","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"74","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"168\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"DataSourceRDD","Scope":"{\"id\":\"178\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"178\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200092,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"81","sql.streaming.queryId":"faf9fcb3-f05f-405c-b2f3-266f89c764de","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"1","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 1","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"74","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerJobStart","Job ID":27,"Submission Time":1759076200107,"Stage Infos":[{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":92,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"162\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"180\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"DataSourceRDD","Scope":"{\"id\":\"180\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[27],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"80","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"6","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 6","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"73","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":92,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"162\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"180\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"DataSourceRDD","Scope":"{\"id\":\"180\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200109,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"419e48ee-0669-45cb-98df-4289b377859f","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"80","sql.streaming.queryId":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"6","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 6","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"73","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":84,"rootExecutionId":84,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@4c07c059\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5e169a92","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1126,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1127,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1128,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1125,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200117,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"SparkListenerJobStart","Job ID":28,"Submission Time":1759076200117,"Stage Infos":[{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"169\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[91],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"DataSourceRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":91,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[28],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"a63fb51b-85ed-4338-bce3-aed908edefc9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"79","sql.streaming.queryId":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"76","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"169\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[91],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"DataSourceRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":91,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200119,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"a63fb51b-85ed-4338-bce3-aed908edefc9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"79","sql.streaming.queryId":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"3","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 3","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"76","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":85,"rootExecutionId":84,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#96 as string) AS value#109]\nInput [7]: [key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#109]\nArguments: MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@7757b64a\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5e169a92","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#96 as string) AS value#109]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#95, value#96, topic#97, partition#98, offset#99L, timestamp#100, timestampType#101] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1126,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1127,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1128,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1125,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200130,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"SparkListenerJobStart","Job ID":29,"Submission Time":1759076200130,"Stage Infos":[{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":96,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"181\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[95],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"DataSourceRDD","Scope":"{\"id\":\"184\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"184\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[29],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"021060e4-10f0-4893-98aa-7839134220e6","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"82","sql.streaming.queryId":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"75","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":96,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"181\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[95],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"DataSourceRDD","Scope":"{\"id\":\"184\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"184\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200131,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"021060e4-10f0-4893-98aa-7839134220e6","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"82","sql.streaming.queryId":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"2","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 2","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"75","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":24,"Stage Attempt ID":0,"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200084,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":25,"Stage Attempt ID":0,"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200090,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":85,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":30,"Submission Time":1759076200144,"Stage Infos":[{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":99,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"185\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[97],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":97,"Name":"DataSourceRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[30],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"85","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"4","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 4","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"84","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":99,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"185\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[97],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":97,"Name":"DataSourceRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200145,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"09cfa957-99fb-457e-8611-6564d577f779","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"85","sql.streaming.queryId":"24f693b5-3be3-4f74-8672-44527e5c0667","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"4","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 4","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"84","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","name":null,"timestamp":"2025-09-28T16:16:40.595Z"}
{"Event":"SparkListenerTaskStart","Stage ID":26,"Stage Attempt ID":0,"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200644,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":27,"Stage Attempt ID":0,"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200647,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":24,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200084,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076200648,"Failed":false,"Killed":false,"Accumulables":[{"ID":961,"Name":"duration","Update":"523","Value":"523","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":965,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":985,"Name":"internal.metrics.executorDeserializeTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":986,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9477721,"Value":9477721,"Internal":true,"Count Failed Values":true},{"ID":987,"Name":"internal.metrics.executorRunTime","Update":524,"Value":524,"Internal":true,"Count Failed Values":true},{"ID":988,"Name":"internal.metrics.executorCpuTime","Update":15573275,"Value":15573275,"Internal":true,"Count Failed Values":true},{"ID":989,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1017,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":25,"Executor Deserialize CPU Time":9477721,"Executor Run Time":524,"Executor CPU Time":15573275,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"161\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[82],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"176\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"DataSourceRDD","Scope":"{\"id\":\"176\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200080,"Completion Time":1759076200649,"Accumulables":[{"ID":961,"Name":"duration","Value":"523","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":965,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":985,"Name":"internal.metrics.executorDeserializeTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":986,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9477721,"Internal":true,"Count Failed Values":true},{"ID":987,"Name":"internal.metrics.executorRunTime","Value":524,"Internal":true,"Count Failed Values":true},{"ID":988,"Name":"internal.metrics.executorCpuTime","Value":15573275,"Internal":true,"Count Failed Values":true},{"ID":989,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1017,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":24,"Completion Time":1759076200649,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerTaskEnd","Stage ID":25,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200090,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076200648,"Failed":false,"Killed":false,"Accumulables":[{"ID":978,"Name":"duration","Update":"520","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":980,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1020,"Name":"internal.metrics.executorDeserializeTime","Update":21,"Value":21,"Internal":true,"Count Failed Values":true},{"ID":1021,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7483037,"Value":7483037,"Internal":true,"Count Failed Values":true},{"ID":1022,"Name":"internal.metrics.executorRunTime","Update":521,"Value":521,"Internal":true,"Count Failed Values":true},{"ID":1023,"Name":"internal.metrics.executorCpuTime","Update":14830541,"Value":14830541,"Internal":true,"Count Failed Values":true},{"ID":1024,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1052,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":21,"Executor Deserialize CPU Time":7483037,"Executor Run Time":521,"Executor CPU Time":14830541,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"167\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[86],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":86,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"177\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[79],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":79,"Name":"DataSourceRDD","Scope":"{\"id\":\"177\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200085,"Completion Time":1759076200649,"Accumulables":[{"ID":978,"Name":"duration","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":980,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1020,"Name":"internal.metrics.executorDeserializeTime","Value":21,"Internal":true,"Count Failed Values":true},{"ID":1021,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7483037,"Internal":true,"Count Failed Values":true},{"ID":1022,"Name":"internal.metrics.executorRunTime","Value":521,"Internal":true,"Count Failed Values":true},{"ID":1023,"Name":"internal.metrics.executorCpuTime","Value":14830541,"Internal":true,"Count Failed Values":true},{"ID":1024,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1052,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":25,"Completion Time":1759076200650,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":86,"rootExecutionId":77,"description":"\nid = e82bef1a-615f-4174-9543-8a5fe37ecb27\nrunId = 504a73a5-5cf2-452e-a554-7967662dd93c\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#397]\nArguments: [toprettystring(value)#397]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#397]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1234,"metricType":"sum"}]},"time":1759076200677,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":87,"rootExecutionId":72,"description":"\nid = 6566bf38-9f27-45c9-8891-497274cea14c\nrunId = 4ec26920-25c9-4399-ab3a-36c141854e69\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#399]\nArguments: [toprettystring(value)#399]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#399]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1235,"metricType":"sum"}]},"time":1759076200685,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":86,"accumUpdates":[[1234,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":87,"accumUpdates":[[1235,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":87,"time":1759076200692,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":86,"time":1759076200692,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":78,"time":1759076200693,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":72,"time":1759076200693,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":83,"time":1759076200693,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":77,"time":1759076200693,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","name":null,"timestamp":"2025-09-28T16:16:40.000Z","batchId":5,"batchDuration":753,"durationMs":{"triggerExecution":753,"queryPlanning":10,"getBatch":0,"commitOffsets":60,"latestOffset":6,"addBatch":642,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":80}}","endOffset":"{\"test-topic\":{\"0\":90}}","latestOffset":"{\"test-topic\":{\"0\":90}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":13.280212483399735,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","name":null,"timestamp":"2025-09-28T16:16:40.000Z","batchId":3,"batchDuration":757,"durationMs":{"triggerExecution":757,"queryPlanning":11,"getBatch":0,"commitOffsets":62,"latestOffset":6,"addBatch":641,"walCommit":34},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":80}}","endOffset":"{\"test-topic\":{\"0\":90}}","latestOffset":"{\"test-topic\":{\"0\":90}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":13.21003963011889,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":88,"rootExecutionId":88,"description":"\nid = b02bad3c-cc78-436b-b4e9-2d8c2908fd81\nrunId = 524a40e4-dec6-422c-9d6e-3f64ff4b31c9\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#374, value#375, topic#376, partition#377, offset#378L, timestamp#379, timestampType#380]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#375 as string) AS value#388]\nInput [7]: [key#374, value#375, topic#376, partition#377, offset#378L, timestamp#379, timestampType#380]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#388]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@707b7c9d\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5c0b7c6e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#375 as string) AS value#388]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#374, value#375, topic#376, partition#377, offset#378L, timestamp#379, timestampType#380] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1237,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1238,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1239,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1236,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200775,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":89,"rootExecutionId":88,"description":"\nid = b02bad3c-cc78-436b-b4e9-2d8c2908fd81\nrunId = 524a40e4-dec6-422c-9d6e-3f64ff4b31c9\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#374, value#375, topic#376, partition#377, offset#378L, timestamp#379, timestampType#380]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [1]: [cast(value#375 as string) AS value#388]\nInput [7]: [key#374, value#375, topic#376, partition#377, offset#378L, timestamp#379, timestampType#380]\n\n(3) WriteToDataSourceV2\nInput [1]: [value#388]\nArguments: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5e11338c\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]], org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2306/0x000000084101c040@5c0b7c6e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(value#375 as string) AS value#388]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#374, value#375, topic#376, partition#377, offset#378L, timestamp#379, timestampType#380] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1237,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1238,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1239,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1236,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1759076200792,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":89,"accumUpdates":[]}
{"Event":"SparkListenerJobStart","Job ID":31,"Submission Time":1759076200808,"Stage Infos":[{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":103,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"199\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[31],"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"89","sql.streaming.queryId":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = b02bad3c-cc78-436b-b4e9-2d8c2908fd81\nrunId = 524a40e4-dec6-422c-9d6e-3f64ff4b31c9\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"88","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":103,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"199\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200809,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.driver.port":"33843","spark.submit.pyFiles":"*********(redacted)","spark.app.startTime":"1759075618190","spark.rdd.compress":"True","callSite.short":"start at NativeMethodAccessorImpl.java:0","__is_continuous_processing":"false","spark.jobGroup.id":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.submitTime":"1759075618021","spark.sql.adaptive.enabled":"false","spark.eventLog.dir":"/tmp/spark-events","spark.app.initial.jar.urls":"*********(redacted)","spark.sql.execution.id":"89","sql.streaming.queryId":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","spark.sql.warehouse.dir":"file:/home/jovyan/work/spark-warehouse","streaming.sql.batchId":"0","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","spark.master":"spark://spark-master:7077","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1","spark.job.interruptOnCancel":"true","spark.repl.local.jars":"*********(redacted)","spark.executor.id":"driver","spark.ui.port":"4040","spark.app.name":"KafkaTestStreaming","spark.submit.deployMode":"client","spark.sql.streaming.checkpointLocation":"/tmp/checkpoint","spark.driver.host":"306c10bfc250","spark.app.id":"app-20250928160659-0004","spark.job.description":"\nid = b02bad3c-cc78-436b-b4e9-2d8c2908fd81\nrunId = 524a40e4-dec6-422c-9d6e-3f64ff4b31c9\nbatch = 0","spark.eventLog.enabled":"true","spark.sql.cbo.enabled":"false","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","spark.files":"*********(redacted)","spark.jars":"*********(redacted)","spark.app.initial.file.urls":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.execution.root.id":"88","spark.serializer.objectStreamReset":"100","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false"}}
{"Event":"SparkListenerTaskStart","Stage ID":31,"Stage Attempt ID":0,"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200813,"Executor ID":"0","Host":"172.18.0.8","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":31,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200813,"Executor ID":"0","Host":"172.18.0.8","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076200838,"Failed":false,"Killed":false,"Accumulables":[{"ID":1240,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":1241,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10050905,"Value":10050905,"Internal":true,"Count Failed Values":true},{"ID":1242,"Name":"internal.metrics.executorRunTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true},{"ID":1243,"Name":"internal.metrics.executorCpuTime","Update":2056591,"Value":2056591,"Internal":true,"Count Failed Values":true},{"ID":1244,"Name":"internal.metrics.resultSize","Update":1209,"Value":1209,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":10050905,"Executor Run Time":2,"Executor CPU Time":2056591,"Peak Execution Memory":0,"Result Size":1209,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":103,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"199\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200809,"Completion Time":1759076200838,"Accumulables":[{"ID":1240,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":1241,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10050905,"Internal":true,"Count Failed Values":true},{"ID":1242,"Name":"internal.metrics.executorRunTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":1243,"Name":"internal.metrics.executorCpuTime","Value":2056591,"Internal":true,"Count Failed Values":true},{"ID":1244,"Name":"internal.metrics.resultSize","Value":1209,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":31,"Completion Time":1759076200839,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":90,"rootExecutionId":88,"description":"\nid = b02bad3c-cc78-436b-b4e9-2d8c2908fd81\nrunId = 524a40e4-dec6-422c-9d6e-3f64ff4b31c9\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#409]\nArguments: <empty>, [toprettystring(value)#409]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan <empty>, [toprettystring(value)#409]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1275,"metricType":"sum"}]},"time":1759076200847,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":90,"accumUpdates":[[1275,0]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":90,"time":1759076200849,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":89,"time":1759076200849,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":88,"time":1759076200849,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","name":null,"timestamp":"2025-09-28T16:16:40.597Z","batchId":0,"batchDuration":275,"durationMs":{"triggerExecution":275,"queryPlanning":16,"getBatch":2,"commitOffsets":22,"latestOffset":56,"addBatch":86,"walCommit":90},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":null,"endOffset":"{\"test-topic\":{\"0\":90}}","latestOffset":"{\"test-topic\":{\"0\":90}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":0,"metrics":{}},"observedMetrics":{}}}
{"Event":"SparkListenerTaskStart","Stage ID":28,"Stage Attempt ID":0,"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076201195,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":27,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200647,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076201196,"Failed":false,"Killed":false,"Accumulables":[{"ID":962,"Name":"duration","Update":"518","Value":"518","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":966,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1090,"Name":"internal.metrics.executorDeserializeTime","Update":24,"Value":24,"Internal":true,"Count Failed Values":true},{"ID":1091,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8016213,"Value":8016213,"Internal":true,"Count Failed Values":true},{"ID":1092,"Name":"internal.metrics.executorRunTime","Update":519,"Value":519,"Internal":true,"Count Failed Values":true},{"ID":1093,"Name":"internal.metrics.executorCpuTime","Update":16107496,"Value":16107496,"Internal":true,"Count Failed Values":true},{"ID":1094,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1122,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":83716144,"JVMOffHeapMemory":85498472,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":174747,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":174747,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16798984,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":7,"MinorGCTime":65,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":65},"Task Metrics":{"Executor Deserialize Time":24,"Executor Deserialize CPU Time":8016213,"Executor Run Time":519,"Executor CPU Time":16107496,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":92,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"162\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"180\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"DataSourceRDD","Scope":"{\"id\":\"180\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200109,"Completion Time":1759076201197,"Accumulables":[{"ID":962,"Name":"duration","Value":"518","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":966,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1090,"Name":"internal.metrics.executorDeserializeTime","Value":24,"Internal":true,"Count Failed Values":true},{"ID":1091,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8016213,"Internal":true,"Count Failed Values":true},{"ID":1092,"Name":"internal.metrics.executorRunTime","Value":519,"Internal":true,"Count Failed Values":true},{"ID":1093,"Name":"internal.metrics.executorCpuTime","Value":16107496,"Internal":true,"Count Failed Values":true},{"ID":1094,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1122,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":27,"Completion Time":1759076201197,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":91,"rootExecutionId":73,"description":"\nid = f3cbff4f-088f-44f4-aaa9-8c7a78288de5\nrunId = 419e48ee-0669-45cb-98df-4289b377859f\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#416]\nArguments: [toprettystring(value)#416]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#416]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1276,"metricType":"sum"}]},"time":1759076201211,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":91,"accumUpdates":[[1276,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":91,"time":1759076201219,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":80,"time":1759076201221,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":73,"time":1759076201221,"errorMessage":""}
{"Event":"SparkListenerTaskStart","Stage ID":29,"Stage Attempt ID":0,"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076201245,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":26,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076200644,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076201245,"Failed":false,"Killed":false,"Accumulables":[{"ID":964,"Name":"duration","Update":"564","Value":"564","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":974,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1055,"Name":"internal.metrics.executorDeserializeTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":1056,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7599822,"Value":7599822,"Internal":true,"Count Failed Values":true},{"ID":1057,"Name":"internal.metrics.executorRunTime","Update":567,"Value":567,"Internal":true,"Count Failed Values":true},{"ID":1058,"Name":"internal.metrics.executorCpuTime","Update":32410134,"Value":32410134,"Internal":true,"Count Failed Values":true},{"ID":1059,"Name":"internal.metrics.resultSize","Update":2587,"Value":2587,"Internal":true,"Count Failed Values":true},{"ID":1060,"Name":"internal.metrics.jvmGCTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":1061,"Name":"internal.metrics.resultSerializationTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":1087,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":83716144,"JVMOffHeapMemory":85498472,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":174747,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":174747,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16798984,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":7,"MinorGCTime":65,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":65},"Task Metrics":{"Executor Deserialize Time":20,"Executor Deserialize CPU Time":7599822,"Executor Run Time":567,"Executor CPU Time":32410134,"Peak Execution Memory":0,"Result Size":2587,"JVM GC Time":4,"Result Serialization Time":5,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"168\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"DataSourceRDD","Scope":"{\"id\":\"178\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"178\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200092,"Completion Time":1759076201246,"Accumulables":[{"ID":964,"Name":"duration","Value":"564","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":974,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1055,"Name":"internal.metrics.executorDeserializeTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":1056,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7599822,"Internal":true,"Count Failed Values":true},{"ID":1057,"Name":"internal.metrics.executorRunTime","Value":567,"Internal":true,"Count Failed Values":true},{"ID":1058,"Name":"internal.metrics.executorCpuTime","Value":32410134,"Internal":true,"Count Failed Values":true},{"ID":1059,"Name":"internal.metrics.resultSize","Value":2587,"Internal":true,"Count Failed Values":true},{"ID":1060,"Name":"internal.metrics.jvmGCTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":1061,"Name":"internal.metrics.resultSerializationTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":1087,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":26,"Completion Time":1759076201246,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","name":null,"timestamp":"2025-09-28T16:16:40.000Z","batchId":6,"batchDuration":1251,"durationMs":{"triggerExecution":1251,"queryPlanning":10,"getBatch":0,"commitOffsets":30,"latestOffset":5,"addBatch":1170,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":80}}","endOffset":"{\"test-topic\":{\"0\":90}}","latestOffset":"{\"test-topic\":{\"0\":90}}","numInputRows":10,"inputRowsPerSecond":1.000100010001,"processedRowsPerSecond":7.9936051159072745,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":92,"rootExecutionId":74,"description":"\nid = faf9fcb3-f05f-405c-b2f3-266f89c764de\nrunId = 49c7d969-da4c-4aab-ad94-f9866f3a7ed0\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#423]\nArguments: [toprettystring(value)#423]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#423]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1277,"metricType":"sum"}]},"time":1759076201265,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":92,"accumUpdates":[[1277,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":92,"time":1759076201269,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":81,"time":1759076201271,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":74,"time":1759076201272,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","name":null,"timestamp":"2025-09-28T16:16:40.001Z","batchId":1,"batchDuration":1292,"durationMs":{"triggerExecution":1292,"queryPlanning":8,"getBatch":1,"commitOffsets":20,"latestOffset":11,"addBatch":1221,"walCommit":31},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":80}}","endOffset":"{\"test-topic\":{\"0\":90}}","latestOffset":"{\"test-topic\":{\"0\":90}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":7.739938080495356,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"SparkListenerTaskStart","Stage ID":30,"Stage Attempt ID":0,"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076201737,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":28,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076201195,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076201738,"Failed":false,"Killed":false,"Accumulables":[{"ID":963,"Name":"duration","Update":"520","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":971,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1129,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":1130,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7519672,"Value":7519672,"Internal":true,"Count Failed Values":true},{"ID":1131,"Name":"internal.metrics.executorRunTime","Update":522,"Value":522,"Internal":true,"Count Failed Values":true},{"ID":1132,"Name":"internal.metrics.executorCpuTime","Update":19272410,"Value":19272410,"Internal":true,"Count Failed Values":true},{"ID":1133,"Name":"internal.metrics.resultSize","Update":2544,"Value":2544,"Internal":true,"Count Failed Values":true},{"ID":1134,"Name":"internal.metrics.jvmGCTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":1161,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":7519672,"Executor Run Time":522,"Executor CPU Time":19272410,"Peak Execution Memory":0,"Result Size":2544,"JVM GC Time":4,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"169\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[91],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"DataSourceRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":91,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200119,"Completion Time":1759076201740,"Accumulables":[{"ID":963,"Name":"duration","Value":"520","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":971,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1129,"Name":"internal.metrics.executorDeserializeTime","Value":12,"Internal":true,"Count Failed Values":true},{"ID":1130,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7519672,"Internal":true,"Count Failed Values":true},{"ID":1131,"Name":"internal.metrics.executorRunTime","Value":522,"Internal":true,"Count Failed Values":true},{"ID":1132,"Name":"internal.metrics.executorCpuTime","Value":19272410,"Internal":true,"Count Failed Values":true},{"ID":1133,"Name":"internal.metrics.resultSize","Value":2544,"Internal":true,"Count Failed Values":true},{"ID":1134,"Name":"internal.metrics.jvmGCTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":1161,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":28,"Completion Time":1759076201740,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":93,"rootExecutionId":76,"description":"\nid = 6c8b7813-2ad1-4494-aaa1-f18f20828a05\nrunId = a63fb51b-85ed-4338-bce3-aed908edefc9\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#430]\nArguments: [toprettystring(value)#430]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#430]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1278,"metricType":"sum"}]},"time":1759076201755,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":93,"accumUpdates":[[1278,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":93,"time":1759076201759,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":79,"time":1759076201760,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":76,"time":1759076201760,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","name":null,"timestamp":"2025-09-28T16:16:40.000Z","batchId":3,"batchDuration":1778,"durationMs":{"triggerExecution":1778,"queryPlanning":8,"getBatch":1,"commitOffsets":18,"latestOffset":6,"addBatch":1708,"walCommit":37},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":80}}","endOffset":"{\"test-topic\":{\"0\":90}}","latestOffset":"{\"test-topic\":{\"0\":90}}","numInputRows":10,"inputRowsPerSecond":1.000100010001,"processedRowsPerSecond":5.62429696287964,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":29,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076201245,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076201781,"Failed":false,"Killed":false,"Accumulables":[{"ID":977,"Name":"duration","Update":"513","Value":"513","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":979,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1164,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":1165,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8917817,"Value":8917817,"Internal":true,"Count Failed Values":true},{"ID":1166,"Name":"internal.metrics.executorRunTime","Update":514,"Value":514,"Internal":true,"Count Failed Values":true},{"ID":1167,"Name":"internal.metrics.executorCpuTime","Update":12277933,"Value":12277933,"Internal":true,"Count Failed Values":true},{"ID":1168,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1196,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":8917817,"Executor Run Time":514,"Executor CPU Time":12277933,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":96,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"181\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[95],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"DataSourceRDD","Scope":"{\"id\":\"184\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"184\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200131,"Completion Time":1759076201782,"Accumulables":[{"ID":977,"Name":"duration","Value":"513","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":979,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1164,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":1165,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8917817,"Internal":true,"Count Failed Values":true},{"ID":1166,"Name":"internal.metrics.executorRunTime","Value":514,"Internal":true,"Count Failed Values":true},{"ID":1167,"Name":"internal.metrics.executorCpuTime","Value":12277933,"Internal":true,"Count Failed Values":true},{"ID":1168,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1196,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":29,"Completion Time":1759076201782,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":94,"rootExecutionId":75,"description":"\nid = df35ef94-6aaf-4a9c-a19f-97e410b52fd2\nrunId = 021060e4-10f0-4893-98aa-7839134220e6\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#437]\nArguments: [toprettystring(value)#437]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#437]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1279,"metricType":"sum"}]},"time":1759076201790,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":94,"accumUpdates":[[1279,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":94,"time":1759076201793,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":82,"time":1759076201794,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":75,"time":1759076201794,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","name":null,"timestamp":"2025-09-28T16:16:40.000Z","batchId":2,"batchDuration":1808,"durationMs":{"triggerExecution":1808,"queryPlanning":8,"getBatch":1,"commitOffsets":14,"latestOffset":6,"addBatch":1742,"walCommit":37},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":80}}","endOffset":"{\"test-topic\":{\"0\":90}}","latestOffset":"{\"test-topic\":{\"0\":90}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":5.530973451327434,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":30,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1759076201737,"Executor ID":"1","Host":"172.18.0.2","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1759076202275,"Failed":false,"Killed":false,"Accumulables":[{"ID":1125,"Name":"duration","Update":"515","Value":"515","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1126,"Name":"number of output rows","Update":"10","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1199,"Name":"internal.metrics.executorDeserializeTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":1200,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7154039,"Value":7154039,"Internal":true,"Count Failed Values":true},{"ID":1201,"Name":"internal.metrics.executorRunTime","Update":517,"Value":517,"Internal":true,"Count Failed Values":true},{"ID":1202,"Name":"internal.metrics.executorCpuTime","Update":14302201,"Value":14302201,"Internal":true,"Count Failed Values":true},{"ID":1203,"Name":"internal.metrics.resultSize","Update":2501,"Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1231,"Name":"internal.metrics.input.recordsRead","Update":10,"Value":10,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":11,"Executor Deserialize CPU Time":7154039,"Executor Run Time":517,"Executor CPU Time":14302201,"Peak Execution Memory":0,"Result Size":2501,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":10},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":99,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"185\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[97],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":97,"Name":"DataSourceRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","Submission Time":1759076200145,"Completion Time":1759076202276,"Accumulables":[{"ID":1125,"Name":"duration","Value":"515","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1126,"Name":"number of output rows","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1199,"Name":"internal.metrics.executorDeserializeTime","Value":11,"Internal":true,"Count Failed Values":true},{"ID":1200,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7154039,"Internal":true,"Count Failed Values":true},{"ID":1201,"Name":"internal.metrics.executorRunTime","Value":517,"Internal":true,"Count Failed Values":true},{"ID":1202,"Name":"internal.metrics.executorCpuTime","Value":14302201,"Internal":true,"Count Failed Values":true},{"ID":1203,"Name":"internal.metrics.resultSize","Value":2501,"Internal":true,"Count Failed Values":true},{"ID":1231,"Name":"internal.metrics.input.recordsRead","Value":10,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":30,"Completion Time":1759076202276,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":95,"rootExecutionId":84,"description":"\nid = 24f693b5-3be3-4f74-8672-44527e5c0667\nrunId = 09cfa957-99fb-457e-8611-6564d577f779\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:251)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [1]: [toprettystring(value)#444]\nArguments: [toprettystring(value)#444]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [toprettystring(value)#444]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1280,"metricType":"sum"}]},"time":1759076202284,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"},"jobTags":[]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":95,"accumUpdates":[[1280,10]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":95,"time":1759076202287,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":85,"time":1759076202288,"errorMessage":""}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":84,"time":1759076202288,"errorMessage":""}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","name":null,"timestamp":"2025-09-28T16:16:40.000Z","batchId":4,"batchDuration":2304,"durationMs":{"triggerExecution":2304,"queryPlanning":11,"getBatch":0,"commitOffsets":16,"latestOffset":8,"addBatch":2186,"walCommit":80},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[test-topic]]","startOffset":"{\"test-topic\":{\"0\":80}}","endOffset":"{\"test-topic\":{\"0\":90}}","latestOffset":"{\"test-topic\":{\"0\":90}}","numInputRows":10,"inputRowsPerSecond":1.0,"processedRowsPerSecond":4.340277777777778,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.execution.streaming.ConsoleTable$@4f6c1428","numOutputRows":10,"metrics":{}},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:17:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:17:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:17:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:17:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:17:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:17:00.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:17:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:17:00.002Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:17:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:17:20.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:17:20.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:17:20.002Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:17:20.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:17:20.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:17:20.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:17:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:17:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:17:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:17:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:17:30.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:17:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:17:40.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:17:40.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:17:40.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:17:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:17:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:17:40.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:17:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:17:40.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:17:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:17:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:17:50.002Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:18:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:18:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:18:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:18:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:18:00.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:18:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:18:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:18:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:18:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:18:20.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:18:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:18:20.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:18:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:18:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:18:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:18:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:18:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:18:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:18:30.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:18:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:18:30.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:18:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:18:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:18:30.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:18:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:18:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:18:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:18:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:18:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:18:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:18:40.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:18:50.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:18:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:18:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:18:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:18:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:18:50.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:19:00.001Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:19:00.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:19:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:19:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:19:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:19:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:19:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:19:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:19:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:19:10.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"24f693b5-3be3-4f74-8672-44527e5c0667","runId":"09cfa957-99fb-457e-8611-6564d577f779","timestamp":"2025-09-28T16:19:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"f3cbff4f-088f-44f4-aaa9-8c7a78288de5","runId":"419e48ee-0669-45cb-98df-4289b377859f","timestamp":"2025-09-28T16:19:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6c8b7813-2ad1-4494-aaa1-f18f20828a05","runId":"a63fb51b-85ed-4338-bce3-aed908edefc9","timestamp":"2025-09-28T16:19:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"df35ef94-6aaf-4a9c-a19f-97e410b52fd2","runId":"021060e4-10f0-4893-98aa-7839134220e6","timestamp":"2025-09-28T16:19:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"faf9fcb3-f05f-405c-b2f3-266f89c764de","runId":"49c7d969-da4c-4aab-ad94-f9866f3a7ed0","timestamp":"2025-09-28T16:19:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"6566bf38-9f27-45c9-8891-497274cea14c","runId":"4ec26920-25c9-4399-ab3a-36c141854e69","timestamp":"2025-09-28T16:19:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"e82bef1a-615f-4174-9543-8a5fe37ecb27","runId":"504a73a5-5cf2-452e-a554-7967662dd93c","timestamp":"2025-09-28T16:19:20.000Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryIdleEvent","id":"b02bad3c-cc78-436b-b4e9-2d8c2908fd81","runId":"524a40e4-dec6-422c-9d6e-3f64ff4b31c9","timestamp":"2025-09-28T16:19:20.000Z"}
{"Event":"SparkListenerApplicationEnd","Timestamp":1759076364875}
